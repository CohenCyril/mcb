% vim:set tw=70:
% vim:set spell:
% vim:set errorformat="":
\begin{coqdef}{name=ssr}
Require Import Ssreflect.ssreflect.
From Ssreflect Require Import ssrfun ssrbool ssrnat eqtype fintype seq div prime.
Set Implicit Arguments.
Unset Strict Implicit.
Unset Printing Implicit Defensive.
\end{coqdef}
\begin{coqdef}{name=abort}
Abort.
\end{coqdef}

\Chapter{Type Inference}{Teaching \Coq{} how to read Math}

%NOTES: Refactoring needed: try to organize the content of this chapter
%and the two following ones along this line:
%\begin{itemize}
%\item First eqTypes, with their theory (and not only the synthesis of
%  the comparison function) and Big operations: this describes
%  ``algebra'', ie. the design of an interface for a (shared) theory
%  and notations.
%\item Then, hierarchies
%\item Then finally how to relate a concrete type to existing,
%  ``isomorphic'' instances of the structures in the hierachy (subType,
%  tuples, CanMixins,...). Here comes the remarks on UIP. May be use
%  the example of how to equip a type with three constructions with all
%  the structures up to finite in the hierarchy (and plug your
%  own preferred datastructure in the framework).
%\end{itemize}
The rules of the \mcbCIC{} are expressed on the syntax on terms and
are implemented by the kernel of \Coq{}.  Such software component
performs \emph{type checking}: given a term and type it checks if such
term has the given type.  To keep type checking simple and decidable
the syntax of terms makes all information explicit. As a consequence
the terms written in such verbose syntax are pretty large.

Luckily the user very rarely interacts directly with the kernel.
Instead she almost always interacts with the refiner, a software
component that is able to accept open terms.  Open terms are in
general way smaller than regular terms because some information can be
left implicit.  In particular one can omit any subterm by writing
``\lstinline/_/'' in place of it.
\marginnote{ I'm a bit uneasy about citations, here I think I want to
add one\cite{Pollack92implicitsyntax}.
They are good readings but a arbitrary and not easy to find.
We should define a policy for citations.}
Each missing piece of information is either reconstructed
automatically by the \emph{type inference} algorithm, or provided
interactively by means of proof commands.  In this chapter we
focus on type inference.

Type inference is \emph{ubiquitous}: whenever the user inputs a term
(or a type) the system tries to infer a type (or
a sort) for it.  One can think of the work of the type inference
algorithm as trying to give a meaning to the input of the
user possibly completing and constraining it by inferring some
information.  If the algorithm succeeds the term is accepted,
otherwise an error is given.

What is crucial to the \mcbMC{} library is that the
type inference algorithm is \emph{programmable}: one can extend the
basic algorithm with small declarative programs that have access to
\marginnote{explain declarative programs}
the library of already formalized facts.  In this way one can make the
type inference algorithm aware of the contents of the library and
make \Coq{} behave as a trained reader that is able to guess the
intended meaning of a mathematical expressions from the context
thanks to his background knowledge.

This chapter introduces the key concepts of \emph{interface}
and \emph{instance}.  An interface is essentially the signature
of an agebraic structure: operations, properties and notations
letting one reason abstractly about a family of objects sharing
the interface.
An instance is an example of an algebraic structure,
an object that fits an interface.  
For example \C{eqType} is the interface of
data types that come equipped with a comparison function, and
the type \C{nat} forms, together with the \C{eqn} function, an
example of \C{eqType}.

The programs we will write to
extend type inference play two roles.  On one hand they link
instances to interfaces, like \C{nat} to \C{eqType}.
On the other hand they build \emph{derived
instances} out of basic ones.  For example we teach type inference
how to synthesize an instance of \C{eqType} for a type like
\C{(A * B)} whenever \C{A} and \C{B} are instances of \C{eqType}.

The concepts of interface and example are recurrent in
both computer science and modern mathematics, but are not a primitive
notion in Coq.  Despite that, they can be encoded quite naturally,
although not trivially, using inductive types and the dependent function
space.   This encoding is not completely orthogonal to the
actual technology (the type inference and its extension mechanism).
For this reason we shall need to dive, from time to time, into
technical details, especially in sections with two stars.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{HO unif is hard}
\mcbREQUIRE{}
\mcbPROVIDE{terminology}
\mcbLEVEL{1}
\mcbsection{Type inference and Higher Order unification}\label{sec:hounif}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The type inference algorithm is quite similar to the type checking
one: it recursively traverses a term checking that each subterm has a
type compatible with the type expected by its context.  During type
checking types are compared taking computation into account.  Terms
that compare as equal are said to be \emph{convertible}.
Termination of reduction and uniqueness of normal forms provide
guidance for implementing the convertibility test, for which a
complete and sound algorithm indeed exists.  Unfortunately type
inference works on open terms, and this fact turns convertibility into
a much harder problem called \emph{higher order unification}.  The
special placeholder ``\lstinline/_/'', usually called \emph{implicit
argument}, may occur inside types and stands for one, and only one,
term that is not explicitly given.  Type inference does not check if
two types are convertible, it checks if they unify.
Unification is allowed to assigning values to implicit arguments in order
to make the resulting terms convertible.  For example unification is
expected to find an assignment that makes the type
\lstinline/(list _)/ convertible to \lstinline/(list nat)/.
By picking the value \lstinline/nat/ for the placeholder
the two types become syntactically equal and hence convertible.
% Unification shall fix the value of an implicit argument only if it
% is strictly needed.

Unfortunately it is not hard to come up with classes of examples where
guessing appropriate values for implicit arguments is, in general, not
possible. In fact such guessing has be shown to be as hard as proof
search in presence of higher order constructs.
For example to unify \lstinline/(prime _)/ with
\lstinline/true/ one has to guess a prime number. Remember that
\lstinline/prime/ is a boolean function that fed with a natural
number returns either \lstinline/true/ or \lstinline/false/.
While assigning \lstinline/2/ to the implicit argument
would be a perfectly valid solution, it is clear
that it is not the only one.  Enumerating all possible
values until one finds a valid one is not a good strategy
either, since the good value may not exist.  Just think at the
problem \lstinline/(prime (4 * _))/ versus \lstinline/true/.  An even
harder class of problems is the one of synthesizing programs.
Take for example the unification problem \lstinline/(_ 17)/ versus
\lstinline/[:: 17]/.  Is the function we are looking for the list
constructor? Or maybe, is it a factorization algorithm?

Given that there is no silver bullet for higher order unification
\Coq{} makes a sensible design choice: provide an (almost)
heuristic-free algorithm and let the user extend it via an extension
language.  We refer to such language as the language of
\emph{Canonical Structures}.  Despite being a very restrictive language,
it is sufficient to program a wide panel of useful functionalities.  The
one described in this chapter can be described as \emph{notation
overloading}.

The concrete syntax for implicit arguments, an underscore character,
does not let one name the missing piece of information.\footnote{This
may change in Coq 8.5}  If an expression contains multiple occurrence
of the placeholder ``\lstinline/_/'' they are all considered as
potentially different by the system, and hence hold (internally)
unique names.  For the sake of clarity we take the freedom to
use the alternative syntax \mcbimpl{x} for implicit arguments (where
$x$ is a unique name).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{type and term inference}
\mcbREQUIRE{have, move, exact}
\mcbPROVIDE{Arguments (setting implicit)}
\mcbLEVEL{1}
\mcbsection{Recap: type inference by examples}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Lets start with the simplest example one could imagine: defining the
polymorphic identity function and checking its application to
\lstinline/3/.

\begin{coq}{name=exid}{width=8cm,title=Polymorphic identity}
Definition id (A : Type) (a : A) : A := a.
Check (id nat 3).
Check (id _ 3).
\end{coq}
\coqrun{name=r1}{exid}
\begin{coqout}{run=r1}{title=Response,width=4cm}

id nat 3 : nat
id nat 3 : nat
\end{coqout}

In the expression \lstinline/(id nat 3)/ no subterm was omitted, and
indeed \Coq{} accepted the term and printed its type.  In the third
line even if the sub term \lstinline/nat/ was omitted, \Coq{} accepted
the term.  Type inference found a value for the place holder
for us by proceeding in the following way:  it traversed the term
recursively from left to right, ensuring that the type of each
argument of the application had the type expected by the function.  In
particular \lstinline/id/ takes two arguments.
The former argument is expected to have type \lstinline/Type/ and the
user left such argument implicit (we name it \mcbimpl{A}).   Type
inference imposes that \mcbimpl{A} has type \lstinline/Type/, and this
constraint is satisfiable.  The algorithm continues checking the
remaining argument.  According to the definition of \lstinline/id/ the type of
the second argument must be the value of the first argument.  Hence
type inference runs recursively on the argument \lstinline/3/
discovering it has type \lstinline/nat/ and imposes that it unifies
with the value of the first argument (that is \mcbimpl{A}).  For this
to be true \mcbimpl{A} has to be assigned the value \lstinline/nat/.
As a result the system prints the input term, where the place holder
has been replaced by the value type inference assigned to it.

At the light of that we observe that every time we apply the identity
function to a term we can omit to specify its first argument,
since \Coq{} is able to infer it and complete the input term for us.
This phenomenon is so frequent that one can ask the system to insert
the right number of \lstinline/_/ for him.  For more details see
Section~\ref{sec:declaringimpl} or refer to the user manual.  Here
we only provide a simple example.

\begin{coq}{name=impl-arg-id}{title=Setting implicit arguments,width=6cm}
Arguments id {A} a.
Check (id 3).
Check (@id nat 3).
\end{coq}
\coqrun{name=iarg}{impl-arg-id}
\begin{coqout}{run=iarg}{title=Response,width=6cm}

id 3 : nat
id 3 : nat
\end{coqout}

The \lstinline/Arguments/ directive ``documents'' the constant
\lstinline/id/.  In this case it just marks then argument that has to
be considered as implicit by surrounding it with curly braces.
The declaration of implicit arguments can be locally disabled by
prefixing the name of the constant with the \lstinline/@/ symbol.

Another piece of information that if often left implicit is
the type of abstracted or quantified variables.

\begin{coq}{name=infarg}{title=Omitting type annotations,width=7cm}
Check (fun x => @id nat x).

Lemma prime_gt1 p : prime p -> 1 < p.
\end{coq}
\coqrun{name=inf}{ssr,infarg,abort}
\begin{coqout}{run=inf}{title=Response,width=5cm}
fun x : nat => id x :
  nat -> nat
$~$
\end{coqout}

In the first line the syntax (\lstinline/fun x => ...)/ is sugar for
\lstinline/(fun x : _ => ...)/ where we leave the type of
\lstinline/x/ open.  Type inference fixes it to \lstinline/nat/
when it reaches the last argument of the identity function.
It unifies the type of \lstinline/x/ with the value of the first
argument given to \lstinline/id/ that in this case is \lstinline/nat/.
This last example is emblematic: most of the times the type of
abstracted variables can be inferred by looking at how they are used.
This is very common in lemma statements.  For example the third line
states a theorem on \lstinline/p/ without explicitly giving its type.
Since the statement uses \lstinline/p/ as the argument of the
\lstinline/prime/ predicate, it is automatically constrained to be
of type \lstinline/nat/.

The kind of information filled in by type inference can also be of
another, more interesting, nature.  So far all place holders were
standing for types, but the user is also allowed to put \lstinline/_/
in place of a term.

\begin{coqdef}{name=infdata}
Lemma example q : prime q -> 0 < q.
Proof.
move=> pr_q. Redirect "g1" Show.
have q_gt1 := @prime_gt1 _ pr_q.
exact: ltnW q_gt1.
Qed.
\end{coqdef}
\begin{coq}{def=infdata}{title=Inferring a term,width=7cm}
Lemma example q : prime q -> 0 < q.
Proof.
move=> pr_q.
have q_gt1 := @prime_gt1 _ pr_q.
exact: ltnW q_gt1.
Qed.
\end{coq}
\coqrun{name=inf2}{ssr,infdata}
\begin{coqout}{run=inf2;out=g1}{title=Goal after line 3,width=5cm}
1 subgoal

q : nat
pr_q : prime q
============================
0 < q
\end{coqout}

The proof begins by giving the name \lstinline/pr_q/ to the assumption
\lstinline/(prime q)/.  Then it builds a proof term by hand using
the lemma stated in the previous example and names it \lstinline/q_gt1/.
In the expression \lstinline/(prime_gt1 _ pr_q)/ the place holder,
that we name \mcbimpl{p}, stands for a natural number.
When type inference reaches \mcbimpl{p} it fixes its type to \lstinline/nat/.
What is more interesting is what happens when type inference reaches the
\lstinline/pr_q/ term.  Such term has its type fixed by the context:
\lstinline/(prime q)/.  The type of the second argument expected by
\lstinline/prime_gt1/ is \lstinline/(prime $\mcbimplm{p}$)/ (i.e. the
type of \lstinline/prime_gt1/ were we substitute \mcbimpl{p} for
\lstinline/p/.  Unifying \lstinline/(prime $\mcbimplm{p}$)/ with
\lstinline/(prime q)/ is possible by assigning \lstinline/q/ to
\mcbimpl{p}.  Hence the proof term just constructed is
well typed, its type is \lstinline/(1 < q)/ and the place holder
has been set to be \lstinline{q}.
As we did for the identity function we can declare the \lstinline/p/
argument of \lstinline/prime_gt1/ as implicit.  \marginnote{maybe also
tell why one does not need two underscores in the last line}
Choosing a good  declaration of implicit arguments for lemmas is
tricky and requires one to think ahead how the lemma is used.
Section~\ref{sec:declaringimpl} is dedicated to that.

So far type inference and in particular unification has been used in
its simplest form, and indeed a first order unification algorithm
incapable of computing or synthesizing functions would have sufficed.
In the next section we introduce the encoding of the relations that
is at the base of the declarative programs we write to
extend unification in the higher order case.
As of today there is no precise, published, documentation of the type
inference and unification algorithms implemented in \Coq{}.  For a
technical presentation of a type inference algorithm close enough to
the one of \Coq{} we suggest the interested reader to
consult~\cite{DBLP:journals/corr/abs-1202-4905}.  The reader
interested in a technical presentation of a simplified version of the
unification algorithm implemented in \Coq{} can
read~\cite{unifcoq,betaderekjournal}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{records as relations, canonical base instances}
\mcbREQUIRE{}
\mcbPROVIDE{Canonical}
\mcbLEVEL{1}
\mcbNOTES{}
\mcbsection{Records as relations}\label{sec:eqtype}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In computes science a record is a very common data structure.  It is a
compound data type, a container with named fields.  Records are
represented faithfully in the \mcbCIC{} as
inductive data types with just one constructor holding all the data.
The peculiarity of the records we are going to use is that they are
dependently typed: the type of each field is allowed to depend on
the values of the fields that precedes it.

\Coq{} provides syntactic sugar for declaring record types.

\begin{coq}{name=eqtype}{}
Record eqType : Type := Pack {
  sort : Type;
  eq_op : sort -> sort -> bool
}.
\end{coq}\label{eqtype:noproof}
\coqrun{name=eqtype1}{ssr,eqtype}

The sentence above declares a new inductive type called
\lstinline/eqType/ with one constructor named
\lstinline/Pack/ with two arguments.  The first one
is named \lstinline/sort/ and holds a type; the second and last
one is called \lstinline/eq_op/ and holds a comparison function
on terms of type \lstinline/sort/.  What this special syntax
does is declaring at once the following inductive type plus
a named projection for each record field:

\begin{coq}{name=eqtype2}{}
Inductive eqType : Type :=
  Pack sort of sort -> sort -> bool.
Definition sort (c : eqType) : Type :=
  let: Pack t _ := c in t.
Definition eq_op (c : eqType) : sort c -> sort c -> bool :=
  let: Pack _ f := c in f.
\end{coq}
\coqrun{name=eqtype2}{ssr,eqtype2}

Note that the type dependency between the two fields requires the first
projection to be used in order to define the type of the second projection.

We think of the \lstinline/eqType/ record type as a relation linking a
data type with a comparison function on that data type.  Before
putting the \lstinline/eqType/ relation to good use we declare an
inhabitant of such type, that we call an \emph{instance}, and we
examine a crucial property of the two projections just defined.

We relate the following comparison function with the \lstinline/nat/
data type: \marginnote{Maybe this function has been shown already}

\begin{coq}{name=eqn}{}
 Fixpoint eqn m n {struct m} :=
  match m, n with
  | 0, 0 => true
  | m'.+1, n'.+1 => eqn m' n'
  | _, _ => false
  end.
Definition nat_eqType : eqType := @Pack nat eqn.
\end{coq}
\coqrun{name=eqn}{ssr,eqtype,eqn}

Projections, when applied to a record instance like
\lstinline/nat_eqType/ compute and extract the desired component.

\begin{coq}{name=redproj}{title=Computation of projections,width=6cm}
Eval simpl in sort nat_eqType.
Eval simpl in @eq_op nat_eqType.
\end{coq}
\coqrun{name=r}{ssr,eqtype,eqn,redproj}
\begin{coqout}{run=r}{title=Response,width=6cm}
= nat : Type
= eqn : sort nat_eqType ->
         sort nat_eqType -> bool
\end{coqout}

\marginnote{Maybe simpl is already explained?}
Given that \lstinline/(sort nat_eqType)/ and \lstinline/nat/
are convertible, equal up to computation, we can use the two terms
interchangeably.  The same holds for \lstinline/(eq_op nat_eqType)/
and \lstinline/eqn/.  Thanks to this fact \Coq{} can type check the
following term:

\begin{coq}{name=eqop}{width=5.7cm}
Check (@eq_op nat_eqType 3 4).
\end{coq}
\coqrun{name=e1}{ssr,eqtype,eqn,eqop}
\begin{coqout}{run=e1}{width=6.3cm}
eq_op 3 4 : bool
\end{coqout}

This term is well typed, but checking it is not as simple as one may
expect.
The \lstinline/eq_op/ function is applied to three arguments.
The first one is \lstinline/nat_eqType/ and its type,
\lstinline/eqType/, is trivially equal to the one expected by
\lstinline/eq_op/.
The following two arguments are hence expected of to be of type
\lstinline/(sort nat_eqType)/ but \lstinline/3/ and \lstinline/4/ are
of type \lstinline/nat/.
Recall that unification takes computation into account exactly as the
convertibility relation.  In this case the unification algorithm
unfolds the definition of \lstinline/nat_eqType/ obtaining
\lstinline/(sort (Pack nat eqn))/ and reduces the projection
extracting  \lstinline/nat/.  The obtained term literally matches the
type of the last two arguments given to \lstinline/eq_op/.

Now, why this complication?  Why should one prefer
\lstinline/(eq_op nat_eqType 3 4)/ to \lstinline/(eqn 3 4)/?
The answer is \emph{overloading}.
It is recurrent in mathematics and computer science to reuse
a symbol, a notation, in two different contexts.  A typical
example coming from the mathematical practice is to use the same
infix symbol $*$ to denote any ring multiplication.  A typical
computer science example is the use of the same infix
\lstinline/==/ symbol to denote the comparison over any data type.
Of course the underlying operation one intends to use depends on
the values it is applied to, or better their type.\footnote{
Actually the meaning of a symbol in math is even deeper: by writing $a
* b$ one expects the reader to figure out from the context which ring
we are talking about, recall its theory, and use this knowledge to
eventually justify the steps that follow in a proof.  This very
same approach let us also model this practice.  We will discuss
it in Section~\ref{sec:...}}
Using records lets us model these practices.
Note that, thanks to its higher order nature, the term \lstinline/eq_op/
can always be the head symbol denoting a comparison.  This makes
it possible to recognize, hence print, comparisons in a uniform way
as well as to input them.  On the contrary, in the simpler expression
\lstinline/(eqn 3 4)/ the name of the head symbol is very specific to
the type of the objects we are comparing.  Also note that
\marginnote{A bit too technical and boring}
polymorphism, in the sense of the \lstinline/ML/ programming language,
is not what we are looking for, since it would impose the comparison
function to behave uniformly on every type.  What we are looking
for is closer to the ad-hoc polymorphism of the \lstinline/Haskell/
programming language or the notion of subtyping provided by object
oriented languages.

In the rest of this chapter we focus on the overloading of the
\lstinline/==/ symbol and we start by defining another comparison
function, this time for the \lstinline/bool/ data type.

\begin{coq}{name=bety}{}
Definition eqb (a b : bool) := if a then b else ~~ b.
Definition bool_eqType : eqType := @Pack bool eqb.
\end{coq}

\marginnote{I need the reader to know something about Notation}
Now the idea is to define a notation that applies to any occurrence
of the \lstinline/eq_op/ head constant and use such
notation for both printing and parsing.

\begin{coqdef}{name=infix}
Notation "x == y" := (@eq_op _ x y).
\end{coqdef}
\begin{coqdef}{name=print}
Check (@eq_op bool_eqType true false).
Check (@eq_op nat_eqType 3 4).
\end{coqdef}
\begin{coq}{name=infix,print}{title=Overloaded notation,width=7cm}
Notation "x == y" := (@eq_op _ x y).
Check (@eq_op bool_eqType true false).
Check (@eq_op nat_eqType 3 4).
\end{coq}
\coqrun{name=r2}{ssr,eqtype,eqn,bety,infix,print}
\begin{coqout}{run=r2}{title=Response,width=5cm}

true == false : bool
3 == 4 : bool
\end{coqout}

As a printing rule, the place holder stands for a wild card: the
notation is used no matter the value of the first argument of
\lstinline/eq_op/.  As a result both occurrences of \lstinline/eq_op/,
line 2 and 3, are printed using the infix \lstinline/==/ syntax.
Of course the two operations are different, they are specific to the
type of the arguments and the typing discipline ensures the
arguments match the type of the comparison function packaged in
the record.

When the notation is used as a parsing rule, the place holder is
interpreted as an implicit argument: type inference is expected to find a value
for it.  Unfortunately such notation does not work as a parsing rule
yet.

\begin{coq}{name=parsenocs}{title=Error,width=6cm}
Check (3 == 4).
\end{coq}
\coqrun{name=nc;fail}{ssr,eqtype,eqn,infix,parsenocs}
\begin{coqout}{run=nc}{title=Response,width=6cm}
Error: The term "3" has type "nat" while it is expected to have type "sort ?e".
\end{coqout}

If we unravel the notation the input term is really
\lstinline/(eq_op _ 3 4)/. We name the place holder \mcbimpl{e}.
If we replay the type inference steps seen before, the unification
step is now failing.  Instead of \lstinline/(sort nat_eqType)/
versus \lstinline/nat/, now unification has to solve the problem
\lstinline/(sort $\mcbimplm{e}$)/ versus \lstinline/nat/.
This problem falls in one of the problematic classes we presented in
Section~\ref{sec:hounif}: the system has to synthesize a comparison
function (or better a record instance containing a comparison
function).

\Coq{} gives up, leaving to the user the task of extending the
unification algorithm with a declarative program that is able to solve
unification problems of the form \lstinline/(sort $\mcbimplm{e}$)/
versus \lstinline/T/ for any \lstinline/T/.
Given the current context it seems reasonable to write an
extension that picks \lstinline/nat_eqType/ when \lstinline/T/ is
\lstinline/nat/ and \lstinline/bool_eqType/ when \lstinline/T/ is
\lstinline/bool/.  In the language of Canonical Structures such
program is expressed as follows.

\begin{coq}{name=declcs}{title=Declaring Canonical Structures}
Canonical nat_eqType.
Canonical bool_eqType.
\end{coq}

The keyword \lstinline/Canonical/ was chosen to stress that the
program is deterministic: each type  \lstinline/T/ is related to
(at most) one \emph{canonical} comparison function.

\begin{coq}{name=parse}{title=Testing CS Inference,width=6cm}
Check (3 == 4).
Check (true == false).
Eval compute in (3 == 4).
\end{coq}
\coqrun{name=cs}{ssr,eqtype,eqn,bety,infix,declcs,parse}
\begin{coqout}{run=cs}{title=Response,width=6cm}
3 == 4 : bool
true == false : bool
= false : bool
\end{coqout}

The mechanics of the small program we wrote using the
\lstinline/Canonical/ keyword can be explained using the
global table of canonical solutions.
Whenever a record instance is declared as canonical \Coq{}
adds to such table an entry for each field of the record type.

\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,width=8cm,center title,tabularx={ll|l},fonttitle=\sffamily\bfseries,title=Canonical Structures Index]
projection & value & solution \\ \hline
\lstinline/sort/ & \lstinline/nat/ & \lstinline/nat_eqType/  \\
\lstinline/sort/ & \lstinline/bool/ & \lstinline/bool_eqType/   \\
%\lstinline/eq_op/ & \lstinline/eqn/ & \lstinline/nat_eqType/  \\
%\lstinline/eq_op/ & \lstinline/eqb/ & \lstinline/bool_eqType/   \\
\hline
\end{tcolorbox}

Whenever a unification problem with the following shape is encountered,
the table of canonical solution is consulted.
\begin{center}
\lstinline/(projection $\mcbimplm{S}$)/ ~~versus~~ \lstinline/value/
\end{center}
The table is looked up using as keys the projection name and the
value.  The corresponding solution is assigned to the implicit
argument \mcbimpl{S}.

In the table we reported only the relevant entries.  Entries
corresponding to the \lstinline/eq_op/ projection play no role
and in the \mcbMC{} library the name of such projections is
usually omitted to signal that fact.

What makes this this approach interesting for a large library is that
record types can play the role of interfaces.  Once a record type has
been defined and some functionality associated to it, like a notation,
one can easily hook a new concept up by defining a corresponding
record instance and declaring it canonical.  One gets immediately all
the functionalities tied to such interface work on the new concept.
For example a user defining new data type with a comparison function
can immediately take advantage of the overloaded \lstinline/==/
notation by packing the type and the comparison function in an
\lstinline/eqType/ instance.

This pattern is so widespread and important that the \mcbMC{}
consistently uses the synonym keyword \lstinline/Structure/ in place of
\lstinline/Record/ in order to make record types playing the role
of interfaces easily recognizable.

Records are first class values in the \mcbCIC{}.  As we have seen
projections are no special, they are simple functions that pattern
match on an inductive data type to access the record fields.  Being
first class citizens means that one can write a term that combines
the fields of two records and builds a new record.  Thanks to this
fact the language of Canonical Structures is able to forge
new record instances by combining the existing ones via a set
of user definable combinators.  This is the subject of the next
section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{derived instances}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{RecCanonical}
\mcbLEVEL{1}
\mcbsection{Records as first class relations}\label{sec:receqtype}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

So far we have used the \lstinline/==/ symbol terms whose type is
atomic, like \lstinline/nat/ or \lstinline/bool/.  If we try for
example to use it on terms whose type was built using a type
constructor like the Cartesian product we encounter an error.

\begin{coq}{name=reccs}{title=Error,width=6cm}
Check (3, true) == (false, 4).
$~$
\end{coq}
\coqrun{name=nc1;fail}{ssr,eqtype,eqn,bety,infix,declcs,reccs}
\begin{coqout}{run=nc1}{title=Response,width=6cm}
Error: The term "(3, true)" has type "(nat * bool)%type" while it is expected to have type "sort ?e".
\end{coqout}

The term \lstinline/(3,true)/ has type \lstinline/(nat * bool)/ and,
so far, we only taught \Coq{} how to compare booleans and natural
numbers, not how to compare pairs.
Intuitively the way to compare pairs is to compare their components
\emph{using the appropriate comparison function}.
Let's write a comparison function for pairs. \marginnote{Do we have
the Sections mechanism here?}

\begin{coq}{name=paircs}{title=Comparing pairs}
Definition prod_cmp eqA eqB x y :=
  @eq_op eqA x.1 y.1 && @eq_op eqB x.2 y.2.
\end{coq}

What is interesting about this comparison function is that the
pairs \lstinline/x/ and \lstinline/y/ are not allowed to have
an arbitrary, product, type here.  The typing constraints imposed
by the two \lstinline/eq_op/ occurrences forces the type of
\lstinline/x/ and \lstinline/y/ to be
\lstinline/(sort eqA * sort eqB)/.  This means
that the records \lstinline/eqA/ and \lstinline/eqB/ hold
a sensible comparison function for, respectively, terms of
type \lstinline/(sort eqA)/ and \lstinline/(sort eqB)/.

It is now sufficient to pack together the Cartesian product type
constructor and this comparison function in an \lstinline/eqType/
instance to extend the canonical structures inference machinery
with a new combinator.

\begin{coq}{name=declcs2}{title=Recursive canonical structure}
Definition prod_eqType (eqA eqB : eqType) : eqType :=
  @Pack (sort eqA * sort eqB) (@prod_cmp eqA eqB).
Canonical prod_eqType.
\end{coq}

The global table of canonical solutions is extended as follows.

\noindent
\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,center title,tabularx={ll|l|l},fonttitle=\sffamily\bfseries,title=Canonical Structures Index]
projection & value & solution & combines solutions for \\ \hline
\lstinline/sort/ & \lstinline/nat/ & \lstinline/nat_eqType/ & \\
\lstinline/sort/ & \lstinline/bool/ & \lstinline/bool_eqType/ &  \\
\lstinline/sort/ & \lstinline/T1 * T2/ & \lstinline/prod_eqType pA pB/
	& \lstinline/pA/ $\leftarrow$ (\lstinline/sort/,\lstinline/T1/),
	  \lstinline/pB/ $\leftarrow$ (\lstinline/sort/,\lstinline/T2/)\\
\hline
\end{tcolorbox}

The third column is empty for base instances while it contains
the recursive calls for instance combinators.  With the updated
table when the unification problem
\begin{center}
\lstinline/(sort $\mcbimplm{e}$)/ ~~versus~~ \lstinline/(T1 * T2)/
\end{center}
is encountered a solution for \mcbimpl{e} is found by proceeding
in the following way.  Two new unification problems are generated:
\lstinline/(sort $\mcbimplm{eqA}$)/ versus \lstinline/T1/ and
\lstinline/(sort $\mcbimplm{eqB}$)/ versus \lstinline/T2/.  If both
are successful and \lstinline/v1/ is the solution for
\mcbimpl{eqA} and \lstinline/v2/ for \mcbimpl{eqB}, the solution for
\mcbimpl{e} is \lstinline/(prod_eqType v1 v2)/.

After the table of canonical solutions has been extended our example
is accepted.\marginnote{no idea if that output can be
produce by \Coq{}}

\begin{coq}{name=parsecs2}{title=Example,width=6.3cm}
Check (3, true) == (4, false).
\end{coq}
\coqrun{name=cs2}{ssr,eqtype,eqn,bety,infix,declcs,paircs,declcs2,parsecs2}
\begin{coqout}{run=cs2}{title=Response,width=5.7cm}
(3, true) == (4, false) : bool
\end{coqout}

The term synthesized by Coq is the folowing one:

\begin{coq}{name=parsecs3}{}
   @eq_op (prod_eqType nat_eqType bool_eqType) (3, true) (4, false).
\end{coq}
\coqrun{name=cs3}{ssr,eqtype,eqn,bety,infix,declcs,paircs,declcs2,parsecs3}

\marginnote{
Make other examples? Other overloaded stuff: maybe and example of
how to hook up to infix in ? or locked? or whatever?
In any case a table with ``all'' the interfaces should probably be
part of the book
}

In the running example of this chapter we use the canonical structures
language to express structurally recursive programs on the syntax
of types.  The \mcbCIC{} allows arbitrary terms to occur inside
types.  As a consequence the language of canonical structures can
express also structurally recursive programs on the syntax
of terms.  This capability is used, for example, in the next
chapter to related Monoid laws to function symbols to model
the syntax and theory of iterated, ``big'', operators.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEVEL{1}
\mcbREQUIRE{records + CS}
\mcbPROVIDE{eqType}
\mcbLEARN{interface to a theory}
\mcbsection{Records as (first class) interfaces}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When we define an overloaded notation we convoy
trough it more than just the arity (or the type) of the associated
operation.  We associate to it a property, or a collection thereof.
For example, in the context of group theory, the infix \C{+} symbol
is typically preferred to \C{*} whenever the group law is
commutative.

Going back to our running example, the actual definition of \lstinline/eqType/
used in the \mcbMC{} library also contains a property.
Indeed there is little one can do with a comparison function if that
function is not ``correct''.  

\begin{coq}{name=eqtype}{title=eqType}
Module Equality.

Structure eqType : Type := Pack {
  sort : Type;
  op : sort -> sort -> bool;
  axiom : forall x y, reflect (x = y) (eq_op x y)
}.

End Equality.
\end{coq}

The extra property turns the
\lstinline/eqType/ relation into a proper \emph{interface},
that fully specifies what \C{op} is.

The axiom says that the boolean comparison function
is compatible with equality: two ground terms compare as equal if and
only if they are syntactically equal.  Note that this means that the
comparison function is not allowed to quotient the type by identifying
two syntactically different terms.

\mantra{The infix notation \lstinline/==/ stands for 
a comparison function compatible with Leibnitz equality
(substitution in any context)}

The \C{Equality} module enclosing the record acts a name space: \C{sort},
\C{eq} and \C{axiom}, three very generic words, are here
made local to the \C{Equality} name space becoming, respectively,
\C{Equality.sort}, \C{Equality.op} and \C{Equality.axiom}.

As in Section~\ref{sec:eqtype}, the record plays the role of
a relation and its \C{sort} component is again the only field
that drives canonical structure inference. Following
a terminology typical of object oriented programming languages,
the set of operations (and properties) that define an interface is
called a class.  In the next chapter we are going to re-use already
defined classes in order to build new ones by mixing-in additional
properties (typically called axioms).
Hence the real, and final, definition of \C{eqType} in the
\mcbMC{} library is the following one:
\marginnote{We assume that \C{rel} is a known concept here}

\begin{coq}{name=eqtype}{title=The read definition of eqType}
Module Equality.

Definition axiom T (e : rel T) := forall x y, reflect (x = y) (e x y).

Record class_of T := Mixin {op : rel T; _ : axiom op}.

Structure eqType : Type := Pack {
  sort :> Type;
  class : class_of sort
}.

End Equality.

Definition eq_op T := Equality.op (Equality.class T).
Notation "x == y" := (@eq_op _ x y).
\end{coq}

In this simple case there is only one property, named
\C{Equality.axiom}.

Said that, nothing really changes: the \C{eqType} structure 
relates a type (called \C{sort}) with a signature (called \C{class}).

Remark the use of \C{:>} instead of \C{:} to type the
field called \C{sort}.  This tells Coq to declare the
\C{Equality.sort} projection
as a coercion, enabling one to write \C{(forall T : eqType, forall x y
: T, P)}.  Ineed \C{T} is not a type, only its \C{sort} projection is.
\gotcha{being \C{Equality.sort} a coercion, it is not displayed by
Coq, hence error messages about a missing canonical structure
declaration typically look very confusing: has type nat but should
have type ?e}

Given the new definition of \lstinline/eqType/,
when we write \lstinline/(a == b)/ type inference does not only infer
a function to compare \lstinline/a/ with \lstinline/b/ but also a
proof that such function is correct.
Indeed declaring the \C{eqType} instance for \C{nat} requires some
extra work:

\begin{coq}{name=eqtype}{title=The complete definition of nat\_eqType}
Lemma eqnP : Equality.axiom eqn.
Proof.
move=> n m; apply: (iffP idP) => [|<-]; last by elim n.
by elim: n m => [|n IHn] [|m] //= /IHn->.
Qed.

Definition nat_eqMixin := Equality.Mixin eqnP.
Canonical nat_eqType := @Equality.Pack nat nat_eqMixin.
\end{coq}

Note that the \C{Canonical} declaration is expanded (showing the
otherwise implicit first argument of \C{Pack}) to document that
we are relating the type \C{nat} with its comparison operation.
\marginnote{This is not exactly as in the .v files, but is way closer
and should ease section 6 (hierarchy)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{overloaded lemmas}
\mcbREQUIRE{}
\mcbPROVIDE{eqP}
\mcbLEVEL{1}
\mcbsection{Using a generic theory}\label{sec:eqtypetheory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The whole point or defining interfaces and linking them with their
examples is to share a theory: a theory proved starting from the
properties of an interface applies to all its instances,
transparently.  In some sense every lemma part of an abstract theory
is \emph{generic}: the very same name can be used for each and every
isntance of the interface, exactly as the \C{==} notation.

The simplest lemma part of the theory of \C{eqType} is the 
\lstinline/eqP/ generic lemma that can be used in conjunction with
any occurrence of the \lstinline/==/ notation.

\begin{coq}{name=eqP}{title=The eqP lemma}
Lemma eqP (T : Equality.eqType) : Equality.axiom (@Equality.op T).
Proof. by case: T => ty [op prop]; exact: prop. Qed.
\end{coq}

The proof is just unpacking the input \lstinline/T/.
We can use it on an concrete example of \C{eqType} like \C{nat}

\begin{coq}{name=test}{title=Use of eqP}
Lemma test (x y : nat) : x == y -> x + y == y + y.
Proof. by move/eqP=> def_x; rewrite def_x. Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}

In short, \C{eqP} can be used to change view: turn any
\C{==} into \C{=} and viceversa.

This also holds on
abstract instances.
When we rework the instance of the type \C{(T1 * T2)} we see that the
proof, by means of the \C{eqP} lemma, uses the axiom of \C{T1} and
\C{T2}.

\begin{coq}{name=eqtype}{title=The complete definition of prod\_eqType}
Section ProdEqType.

Variable T1 T2 : eqType.

Definition pair_eq := [rel u v : T1 * T2 | (u.1 == v.1) && (u.2 == v.2)].

Lemma pair_eqP : Equality.axiom pair_eq.
Proof.
move=> [x1 x2] [y1 y2] /=; apply: (iffP andP) => [[]|[<- <-]] //=.
by move/eqP->; move/eqP->.
Qed.

Definition prod_eqMixin := Equality.Mixin pair_eqP.
Canonical prod_eqType := @Equality.Pack (T1 * T2) prod_eqMixin.

End ProdEqType.
\end{coq}

Like for \C{nat} the generic lemma \C{eqP} also applies to
any \C{eqType} instance, like \C{(bool * nat)}

\begin{coq}{name=test}{title=Use of eqP}
Lemma test (x y : nat) (a b : bool) : (a,x) == (b,y) -> fst (a,x) == b.
Proof. by move/eqP=> def_ax; rewrite def_ax. Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}

The \lstinline/(a,x)$~$== (b,y)/ assumption is reflected to
\lstinline/(a,x)$~$= (b,y)/ by using the \lstinline/eqP/ view
specified by the user.  Here we write \lstinline/==/ to have
all the benefits of a computable function (simplification, reasoning
by cases), but when we need the underlying logical property of
substitutivity we access it via the view \lstinline/eqP/.

\begin{coq}{name=test}{title=Why one should always use \C{==}
	(computation)}
Lemma test (x y : nat) : (true,x) == (false,y) -> false.
Proof. by []. Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}

This is true (or better, the hypothesis is false) by computation.

\begin{coq}{name=test}{title=Why one should always use \C{==} (EM)}
Lemma test (x y : nat) : if x == y.+1 then x != 0 else true.
Proof. by case E: (x == y.+1) => //; rewrite (eqP E). Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}


\marginnote{Maybe here suggest to use ifP and =P if not already known, or
do it now}

\mantra{
	whenever we want to state equality between two expressions, if
	they live in an eq type, always use \lstinline/==/.
}


Note that the proof language silently adjusted the view
using \lstinline/elimT/.

\begin{coq}{name=elimt}{title=The eqtype view,width=5.3cm}
Check elimT.

\end{coq}
\coqrun{name=et}{ssr,elimt}
\begin{coqout}{run=et}{title=Response,width=6.7cm}
elimT : forall (P : Prop) (b : bool),
          reflect P b -> b -> P
\end{coqout}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{eqType is the base of (abstract) ssr style}
\mcbREQUIRE{}
\mcbPROVIDE{\\in}
\mcbLEVEL{1}
\mcbsection{The generic theory of sequences}\label{sec:eqtypetheory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Now that the \lstinline/eqType/ interface equips a type with a well
specified comparison function we can use it build abstract theories,
for example the one of sequences.

It is worth to remark that the concept of interface is scrucial to
the development of such theory.  If we try to develop the theory
of the type \C{(seq T)} for an arbitrary \C{T}, we can't go much far.
For example we can express what belonging to a sequence means, but
not write a program that tests if a value is indeed in the list.  As a
consequence we lose automation and it becomes harder to reason by
cases on the membership predicate.
On the contrary when we quantify a theory on the type  \C{(seq T)} for a
\C{T} that is an \C{eqType}, we recover all that.  In other words
by better specifying the type that parametrizes a generic container
we define which operations are lecit and which properties hold.
So far the only interface we know is \C{eqType}, that is very
connected with the ``small scale reflection'' approach we follow.
In the next chapters more elaborate interface will enable us to
organize knowledge in a more articulated way.

Going back to the abstract theory of sequences over an \C{eqType},
we define the membership operation.

\begin{coq}{name=memseq}{title=Membership}
Section SeqTheory.
Variable T : eqType.
Implicit Type s : seq T.

Fixpoint mem_seq s x :=
  if s is y :: s' then (y == x) && mem_seq s' x else false.
\end{coq}
\coqrun{name=memseq}{ssr,memseq}

Like we did for the overloaded \C{==} notation, we can define the
\C{\\in} (and \C{\\notin}) infix notation.  We can then easily
define what a duplicate free sequence is, and how to enforce such
property.

\begin{coq}{name=uniq}{}
Fixpoint uniq s :=
  if s is x :: s' then (x \notin s') || uniq s' else true.
Fixpoint undup s :=
  if s is x :: s' then
    if x \in s' then undup s' else x :: undup s'
  else [::].
\end{coq}
\coqrun{name=uniq}{ssr,uniq}

Proofs about such concepts can be made pretty much as if
the type \C{T} was \C{nat} or \C{bool}, i.e. the style of proofs
does not change.
\marginnote{requires \C{=i}}

\begin{coq}{name=undupuniq1}{title=\C{undup} is correct (step 1)}
Lemma in_cons y s x : (x \in y :: s) = (x == y) || (x \in s).
Proof. by []. Qed.

Lemma mem_undup s : undup s =i s.
Proof.
move=> x; elim: s => //= y s IHs.
case Hy: (y \in s); last by rewrite in_cons IHs.
by rewrite in_cons IHs; case: eqP => // ->.
Qed.
\end{coq}

The \C{in\_cons} lemms is just a convenience rewrite rule, while
\C{mem\_undup} says that the \C{undup} function does not drop
any non-duplicate element.  Note that in the proof we use both
decidability of membership (\C{Hy}) and then the decidability of
equality (via \C{eqP}).

\begin{coq}{name=undupuniq2}{title=\C{undup} is correct (setp 2)}
Lemma undup_uniq s : uniq (undup s).
Proof.
by elim: s => //= x s IHs; case sx: (x \in s); rewrite //= mem_undup sx.
Qed.
\end{coq}
\coqrun{name=uniqp}{ssr,uniq,undupuniq1,undupuniq2,abort}

This last proof adds no new ingredients, it is there just for
completeness.

The last step in the theory of sequences is to show that the container
preserves the \C{eqType} interface: whenever we can compare the
elements of a sequence, we can also compare sequences.

\begin{coq}{name=seqeqtype}{title=\C{eqType} for sequences}
Fixpoint eqseq s1 s2 {struct s2} :=
  match s1, s2 with
  | [::], [::] => true
  | x1 :: s1', x2 :: s2' => (x1 == x2) && eqseq s1' s2'
  | _, _ => false
  end.

Lemma eqseqP : Equality.axiom eqseq.
Proof.
elim=> [|x1 s1 IHs] [|x2 s2] /=; do? [exact: ReflectT | exact: ReflectF].
case: (x1 =P x2) => [<-|neqx]; last by apply: ReflectF => -[eqx _].
by apply: (iffP (IHs s2)) => [<-|[]].
Qed.

Definition seq_eqMixin := Equality.Mixin eqseqP.
Canonical seq_eqType := @Equality.Pack (seq T) seq_eqMixin.
\end{coq}

As an example we build the a sequence of sequences, and we assert that
we can use the \C{==} and \C{\\in} notation on it, as well as apply
the list operations and theorems on objects of type \C{(seq (seq T))}
when \C{T} is an \C{eqType}.

\begin{coq}{name=itereqtype}{}
Let s1 := [:: 1; 2 ].
Let s2 := [:: 3; 5; 7].
Let ss := [:: s1 ; s2 ].
Check ss == [::] || s1 \in ss.
Check uniq ss.
Check undup_uniq ss.
\end{coq}
\coqrun{name=uniqp2}{ssr,itereqtype}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{bigop}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{overloaded big notations}
\mcbLEVEL{1}
\mcbsection{The generic theory of ``big'' operators}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As already anticipated in the introducetion of this chapter, terms are
allowed to occur inside types and hence canonical structure inference
can be keyed on terms.  This possibility is exploited by the iterated
operations library that provides convenient notations and theories
for iterated, ``big'' operators like
$$
\sum_{i=1}^n f(i)
\quad
\bigcup_{i \in A} g(i)
$$
The theory of big operators depends on the properties the iterated
function, for example one can pull out of a summation an element in
the middle only if the operation is commutative and associative.
Maybe cite Bourbaki, algebra 1, ch 1.

First, lets analyze the notation.  We focus on finite iterations.
The components are a range, a filter, the expression, the iterated
function and the neutral.  The range can be a list (cite iota).
Not sure the filter is so common in math, but is clearly convenient
to pull an \C{if cond then neutral else expr} out of the main body.

For notational purposes it is important to identify the bound
variable, so we pack most components into a box.

\begin{coq}{name=bigop2}{}
Inductive bigbody R I := BigBody of I & (R -> R -> R) & bool & R.
Definition applybig {R I} (body : bigbody R I) x :=
  let: BigBody _ op b v := body in if b then op v x else x.
\end{coq}

Finally, we just use fold.

\begin{coq}{name=bigop3}{}
Definition bigop R I idx r (body : I -> bigbody R I) :=
  foldr (applybig \o body) idx r.
Notation "\big [ op / idx ]_ ( i <- r | P ) F" :=
  (bigop idx r (fun i => BigBody i op P%B F)) : big_scope.
Local Notation "+%N" := addn (at level 0, only parsing).
Notation "\sum_ ( i <- r | P ) F" :=
  (\big[+%N/0%N]_(i <- r | P%B) F%N) : nat_scope.
\end{coq}
\coqrun{name=uniqp2}{ssr,bigop,bigop2}

Explain the generic notation and the one in nat scope.

How many variants should we document here? we can't use ord here, but
the other variants make sense.

\begin{coq}{name=bigop3}{}
Definition index_iota m n := iota m (n - m).
Notation "\big [ op / idx ]_ ( m <= i < n | P ) F" :=
  (bigop idx (index_iota m n) (fun i : nat => BigBody i op P%B F))
     : big_scope.

Notation "\big [ op / idx ]_ ( i 'in' A | P ) F" :=
  (\big[op/idx]_(i | (i \in A) && P) F) : big_scope.

Notation "\big [ op / idx ]_ ( i <- r ) F" :=
  (bigop idx r (fun i => BigBody i op true F)) : big_scope.
\end{coq}

Here we quickly present the minimal interface an operation has to
satisfy in order to be iterated.  Chapter~\ref{..} will add other
interfaces and organize the library around them.

\begin{coq}{name=bigop}{}
Module Monoid.

Section Definitions.
Variables (T : Type) (idm : T).

Structure law := Law {
  operator : T -> T -> T;
  _ : associative operator;
  _ : left_id idm operator;
  _ : right_id idm operator
}.
\end{coq}
\coqrun{name=uniqp2}{ssr,bigop}

Here make the point that the key is the operator.

Now the theory of this interface.

\begin{coq}{name=bigop1}{}
Coercion operator : law >-> Funclass.
Section MonoidProperties.

Variable R : Type.
Variable idx : R.
Variable op : Monoid.law idx.

Notation Local "1" := idx.
Notation Local "*%M" := op (at level 0).
Notation Local "x * y" := (op x y).
	
Lemma big1_eq I r (P : pred I) : \big[*%M/1]_(i <- r | P i) 1 = 1.

(* Another one used later on *)
Lemma big_cat I r1 r2 (P : pred I) F :
  \big[*%M/1]_(i <- r1 ++ r2 | P i) F i =
     \big[*%M/1]_(i <- r1 | P i) F i * \big[*%M/1]_(i <- r2 | P i) F i.
\end{coq}
\coqrun{name=uniqp2}{ssr,bigop}

Help to read the statements.

Explain that operator is a coercion and is inserted in bog body.

\begin{coq}{name=natmonoid}{}
Canonical addn_monoid := Law addnA add0n addn0.
\end{coq}

This adds the following

\noindent
\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,width=8cm,center title,tabularx={ll|l},fonttitle=\sffamily\bfseries,title=Canonical Structures Index]
projection & value & solution \\ \hline
\lstinline/operator/ & \lstinline/addn/ & \lstinline/addn_monoid/  \\
\hline
\end{tcolorbox}

Then show in action.

\begin{coq}{name=bigop2}{}
Lemma test l : \sum_(i <- l) 0 = 0.
Proof. by rewrite big1_eq. Qed.
\end{coq}

\C{(BigBody i addn true 0)} versus \C{(BigBody i (operator ?m) (?P i) (?F i))}.
Mention that ?P and ?F are hard too, but in general they work.

In short TI finds out that 0 is neutral for addn (the key of CS
inference), hence the overloaded lemma applies here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Declaring overloaded notations}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{Notation}
\mcbLEVEL{2}
\mcbsection{Working with overloaded notations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This little section deals with two ``technological issues'' the reader
may need to know in order to define overloaded notations or work
comfortably with them.

The first one is the necessity ot tune the behavior of the
simplification tactic (the \C{/=} switch) to avoid loosing the
heand constant to which the overloaded notation is attached.
For example the following term:

\begin{coq}{name=infix,print}{}
  (@eq_op bool_eqType true false).
\end{coq}

can be simplifies (reduced) to the following one

\begin{coq}{name=infix,print}{}
  (@eqb true false).
\end{coq}

While the two terms are logically equivalent (i.e. the logic cannot
distinguish them) the pretty printer can.  Indeed the overloaded
\C{==} notation is attached to the \C{eq\_op} constant, and if such
constant fades away the notation follows it.  Coq lets one declare
constants that should not be automatically simplifies away, unless the
occur in a context that demands it.

\begin{coq}{name=infix,print}{}
Arguments eq_op {_} _ _ : simpl never.
Eval simpl in forall x y : bool, x == y.
Eval simpl in forall x y : bool, true == false || x == y.
\end{coq}

The first call to \C{simpl} does not reduce away \C{eq\_op}
leaving the expression untouched.  In the second example, it
does reduce to \C{false} the test \C{(true == false)} in order to
simplify the \C{||} connective.

The converse technological issue may arise when cnaonical structure
inference ``promotes'' ....

\begin{coq}{name=infix,print}{}
Lemma xxx F l1 l2 : \sum_(i <- l1 ++ l2) F i = \sum_(i <- l2 ++ l1) F i.
Proof.
rewrite big_cat.  (* show here *)
rewrite /=.
by rewrite addnC -big_cat.
Qed.
\end{coq}

It is not uncommon to see \C{/=} switch in purely algebraic proofs
(where no computation is really involved) just to clean up the display
of the current conjecture.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Implement \lstinline/[foo of nat]/}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{Phantom}
\mcbLEVEL{3}
\mcbsection{Triggering type inference}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Sometime one wants to force a type parameter to stand for a type that
satisfies a given interface.  For example a set data structure may
require its elements to be eqtypes.  (well, fintype in the
library...).  So one want to let the user write \C{\{set nat\}} or
\C{\{set (nat * nat)\}} and have the system accept such notation only
if the type parametner is an eqtype.

\begin{coq}{name=phantom}{}
CoInductive phant (p : Type) := Phant.
\end{coq}

An example

\begin{coq}{name=set}{}
Variable T : eqType.
Definition set_of of phant T := seq T.  (* show sort here *)
Notation "{ 'set' T }" := (set_of (Phant T))
  (at level 0, format "{ 'set'  T }") : type_scope.
Check {set nat}.
Fail Check {set (nat -> nat)}.
\end{coq}

Points: lifting a term into a type; notations are untyped (needed?).

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \mcbLEARN{difference with type classes, limitations}
% \mcbREQUIRE{RecCanonical,Coqercions}
% \mcbPROVIDE{}
% \mcbLEVEL{2}
% \mcbsection{Discussion about type inference}\label{sec:typeinfrelated}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% NOT sure I want to keep that discussion.
% 
% The points I want to make are:
% \begin{itemize}
% \item during type inference, HO infers (morally) the minimum
% 	info necessary to make things well typed (if we were 1st order
% 	that would really be true).
% 	hence we KNOW when CS inference is triggered EXACTLY.
% 	this is a big difference w.r.t. type classes. It is like a
% 	Prolog program where goals are reordered randomly
% \item I also want to talk about the overlapping instances problem,
% 	that is ``easy'' with TC, hard with CS and envisage an
% 	extension.
% \item limitation of coercions, from both the usability perspective and
% 	the expressive power they offer
% \end{itemize}
