% vim:set tw=70:
% vim:set spell:
% vim:set errorformat="":
\begin{coqdef}{name=ssr}
Require Import Ssreflect.ssreflect.
From Ssreflect Require Import ssrfun ssrbool ssrnat eqtype fintype seq div prime.
Set Implicit Arguments.
Unset Strict Implicit.
Unset Printing Implicit Defensive.
\end{coqdef}
\begin{coqdef}{name=abort}
Abort.
\end{coqdef}

\Chapter{Type Inference}{ Teaching \Coq{} how to read Math}

%NOTES: Refactoring needed: try to organize the content of this chapter
%and the two following ones along this line:
%\begin{itemize}
%\item First eqTypes, with their theory (and not only the synthesis of
%  the comparison function) and Big operations: this describes
%  ``algebra'', ie. the design of an interface for a (shared) theory
%  and notations.
%\item Then, hierarchies
%\item Then finally how to relate a concrete type to existing,
%  ``isomorphic'' instances of the structures in the hierachy (subType,
%  tuples, CanMixins,...). Here comes the remarks on UIP. May be use
%  the example of how to equip a type with three constructions with all
%  the structures up to finite in the hierarchy (and plug your
%  own preferred datastructure in the framework).
%\end{itemize}
The rules of the \mcbCIC{} are expressed on the syntax on terms and
are implemented by the kernel of \Coq{}.  Such software component
performs \emph{type checking}: given a term and type it checks if such
term has the given type.  To keep type checking simple and decidable
the syntax of terms makes all information explicit. As a consequence
the terms written in such verbose syntax are pretty large.

Luckily the user very rarely interacts directly with the kernel.
Instead she almost always interacts with the refiner, a software
component that is able to accept open terms.  Open terms are in
general way smaller than regular terms because some information can be
left implicit.  In particular one can omit any subterm by writing
``\lstinline/_/'' in place of it.
\marginnote{ I'm a bit uneasy about citations, here I think I want to
add one\cite{Pollack92implicitsyntax}.
They are good readings but a arbitrary and not easy to find.
We should define a policy for citations.}
Each missing piece of information is either reconstructed
automatically by the \emph{type inference} algorithm, or provided
interactively by means of proof commands.  In this chapter we
focus on type inference.

Type inference is \emph{ubiquitous}: whenever the user inputs a term
(or a type) the system tries to infer a type (or
a sort) for it.  One can think of the work of the type inference
algorithm as trying to give a meaning to the input of the
user possibly completing and constraining it by inferring some
information.  If the algorithm succeeds the term is accepted,
otherwise an error is given.

What is crucial to the \mcbMC{} library is that the
type inference algorithm is \emph{programmable}: one can extend the
basic algorithm with small declarative programs that have access to
\marginnote{explain declarative programs}
the library of already formalized facts.  In this way one can make the
type inference algorithm aware of the contents of the library and
make \Coq{} behave as a trained reader that is able to guess the
intended meaning of a mathematical expressions from the context
thanks to his background knowledge.

This chapter introduces the key concepts of \emph{interface}
and \emph{instance}.  An interface is essentially the signature
of an agebraic structure: operations, properties and notations
letting one reason abstractly about a family of objects sharing
the interface.
An instance is an example of an algebraic structure,
an object that fits an interface.
For example \C{eqType} is the interface of
data types that come equipped with a comparison function, and
the type \C{nat} forms, together with the \C{eqn} function, an
example of \C{eqType}.

The programs we will write to
extend type inference play two roles.  On one hand they link
instances to interfaces, like \C{nat} to \C{eqType}.
On the other hand they build \emph{derived
instances} out of basic ones.  For example we teach type inference
how to synthesize an instance of \C{eqType} for a type like
\C{(A * B)} whenever \C{A} and \C{B} are instances of \C{eqType}.

The concepts of interface and example are recurrent in
both computer science and modern mathematics, but are not a primitive
notion in \Coq{}.  Despite that, they can be encoded quite naturally,
although not trivially, using inductive types and the dependent function
space.   This encoding is not completely orthogonal to the
actual technology (the type inference and its extension mechanism).
For this reason we shall need to dive, from time to time, into
technical details, especially in sections with two stars.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{HO unif is hard}
\mcbREQUIRE{}
\mcbPROVIDE{terminology}
\mcbLEVEL{1}
\mcbsection{Type inference and Higher Order unification}\label{sec:hounif}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The type inference algorithm is quite similar to the type checking
one: it recursively traverses a term checking that each subterm has a
type compatible with the type expected by its context.  During type
checking types are compared taking computation into account.  Terms
that compare as equal are said to be \emph{convertible}.
Termination of reduction and uniqueness of normal forms provide
guidance for implementing the convertibility test, for which a
complete and sound algorithm indeed exists.  Unfortunately type
inference works on open terms, and this fact turns convertibility into
a much harder problem called \emph{higher order unification}.  The
special placeholder ``\lstinline/_/'', usually called \emph{implicit
argument}, may occur inside types and stands for one, and only one,
term that is not explicitly given.  Type inference does not check if
two types are convertible, it checks if they unify.
Unification is allowed to assigning values to implicit arguments in order
to make the resulting terms convertible.  For example unification is
expected to find an assignment that makes the type
\lstinline/(list _)/ convertible to \lstinline/(list nat)/.
By picking the value \lstinline/nat/ for the placeholder
the two types become syntactically equal and hence convertible.
% Unification shall fix the value of an implicit argument only if it
% is strictly needed.

Unfortunately it is not hard to come up with classes of examples where
guessing appropriate values for implicit arguments is, in general, not
possible. In fact such guessing has be shown to be as hard as proof
search in presence of higher order constructs.
For example to unify \lstinline/(prime _)/ with
\lstinline/true/ one has to guess a prime number. Remember that
\lstinline/prime/ is a boolean function that fed with a natural
number returns either \lstinline/true/ or \lstinline/false/.
While assigning \lstinline/2/ to the implicit argument
would be a perfectly valid solution, it is clear
that it is not the only one.  Enumerating all possible
values until one finds a valid one is not a good strategy
either, since the good value may not exist.  Just think at the
problem \lstinline/(prime (4 * _))/ versus \lstinline/true/.  An even
harder class of problems is the one of synthesizing programs.
Take for example the unification problem \lstinline/(_ 17)/ versus
\lstinline/[:: 17]/.  Is the function we are looking for the list
constructor? Or maybe, is it a factorization algorithm?

Given that there is no silver bullet for higher order unification
\Coq{} makes a sensible design choice: provide an (almost)
heuristic-free algorithm and let the user extend it via an extension
language.  We refer to such language as the language of
\emph{Canonical Structures}.  Despite being a very restrictive language,
it is sufficient to program a wide panel of useful functionalities.  The
one described in this chapter can be described as \emph{notation
overloading}.

The concrete syntax for implicit arguments, an underscore character,
does not let one name the missing piece of information.\footnote{This
may change in \Coq{} 8.5}  If an expression contains multiple occurrence
of the placeholder ``\lstinline/_/'' they are all considered as
potentially different by the system, and hence hold (internally)
unique names.  For the sake of clarity we take the freedom to
use the alternative syntax \mcbimpl{x} for implicit arguments (where
$x$ is a unique name).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{type and term inference}
\mcbREQUIRE{have, move, exact}
\mcbPROVIDE{Arguments (setting implicit)}
\mcbLEVEL{1}
\mcbsection{Recap: type inference by examples}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Lets start with the simplest example one could imagine: defining the
polymorphic identity function and checking its application to
\lstinline/3/.

\begin{coq}{name=exid}{width=8cm,title=Polymorphic identity}
Definition id (A : Type) (a : A) : A := a.
Check (id nat 3).
Check (id _ 3).
\end{coq}
\coqrun{name=r1}{exid}
\begin{coqout}{run=r1}{title=Response,width=4cm}

id nat 3 : nat
id nat 3 : nat
\end{coqout}

In the expression \lstinline/(id nat 3)/ no subterm was omitted, and
indeed \Coq{} accepted the term and printed its type.  In the third
line even if the sub term \lstinline/nat/ was omitted, \Coq{} accepted
the term.  Type inference found a value for the place holder
for us by proceeding in the following way:  it traversed the term
recursively from left to right, ensuring that the type of each
argument of the application had the type expected by the function.  In
particular \lstinline/id/ takes two arguments.
The former argument is expected to have type \lstinline/Type/ and the
user left such argument implicit (we name it \mcbimpl{A}).   Type
inference imposes that \mcbimpl{A} has type \lstinline/Type/, and this
constraint is satisfiable.  The algorithm continues checking the
remaining argument.  According to the definition of \lstinline/id/ the type of
the second argument must be the value of the first argument.  Hence
type inference runs recursively on the argument \lstinline/3/
discovering it has type \lstinline/nat/ and imposes that it unifies
with the value of the first argument (that is \mcbimpl{A}).  For this
to be true \mcbimpl{A} has to be assigned the value \lstinline/nat/.
As a result the system prints the input term, where the place holder
has been replaced by the value type inference assigned to it.

At the light of that we observe that every time we apply the identity
function to a term we can omit to specify its first argument,
since \Coq{} is able to infer it and complete the input term for us.
This phenomenon is so frequent that one can ask the system to insert
the right number of \lstinline/_/ for him.  For more details
% see section~\ref{sec:declaringimpl} or
refer to the user manual.  Here
we only provide a simple example.

\begin{coq}{name=impl-arg-id}{title=Setting implicit arguments,width=6cm}
Arguments id {A} a.
Check (id 3).
Check (@id nat 3).
\end{coq}
\coqrun{name=iarg}{impl-arg-id}
\begin{coqout}{run=iarg}{title=Response,width=6cm}

id 3 : nat
id 3 : nat
\end{coqout}

The \lstinline/Arguments/ directive ``documents'' the constant
\lstinline/id/.  In this case it just marks then argument that has to
be considered as implicit by surrounding it with curly braces.
The declaration of implicit arguments can be locally disabled by
prefixing the name of the constant with the \lstinline/@/ symbol.

Another piece of information that if often left implicit is
the type of abstracted or quantified variables.

\begin{coq}{name=infarg}{title=Omitting type annotations,width=7cm}
Check (fun x => @id nat x).

Lemma prime_gt1 p : prime p -> 1 < p.
\end{coq}
\coqrun{name=inf}{ssr,infarg,abort}
\begin{coqout}{run=inf}{title=Response,width=5cm}
fun x : nat => id x :
  nat -> nat
$~$
\end{coqout}

In the first line the syntax (\lstinline/fun x => ...)/ is sugar for
\lstinline/(fun x : _ => ...)/ where we leave the type of
\lstinline/x/ open.  Type inference fixes it to \lstinline/nat/
when it reaches the last argument of the identity function.
It unifies the type of \lstinline/x/ with the value of the first
argument given to \lstinline/id/ that in this case is \lstinline/nat/.
This last example is emblematic: most of the times the type of
abstracted variables can be inferred by looking at how they are used.
This is very common in lemma statements.  For example the third line
states a theorem on \lstinline/p/ without explicitly giving its type.
Since the statement uses \lstinline/p/ as the argument of the
\lstinline/prime/ predicate, it is automatically constrained to be
of type \lstinline/nat/.

The kind of information filled in by type inference can also be of
another, more interesting, nature.  So far all place holders were
standing for types, but the user is also allowed to put \lstinline/_/
in place of a term.

\begin{coqdef}{name=infdata}
Lemma example q : prime q -> 0 < q.
Proof.
move=> pr_q. Redirect "g1" Show.
have q_gt1 := @prime_gt1 _ pr_q.
exact: ltnW q_gt1.
Qed.
\end{coqdef}
\begin{coq}{def=infdata}{title=Inferring a term,width=7cm}
Lemma example q : prime q -> 0 < q.
Proof.
move=> pr_q.
have q_gt1 := @prime_gt1 _ pr_q.
exact: ltnW q_gt1.
Qed.
\end{coq}
\coqrun{name=inf2}{ssr,infdata}
\begin{coqout}{run=inf2;out=g1}{title=Goal after line 3,width=5cm}
1 subgoal

q : nat
pr_q : prime q
============================
0 < q
\end{coqout}

The proof begins by giving the name \lstinline/pr_q/ to the assumption
\lstinline/(prime q)/.  Then it builds a proof term by hand using
the lemma stated in the previous example and names it \lstinline/q_gt1/.
In the expression \lstinline/(prime_gt1 _ pr_q)/ the place holder,
that we name \mcbimpl{p}, stands for a natural number.
When type inference reaches \mcbimpl{p} it fixes its type to \lstinline/nat/.
What is more interesting is what happens when type inference reaches the
\lstinline/pr_q/ term.  Such term has its type fixed by the context:
\lstinline/(prime q)/.  The type of the second argument expected by
\lstinline/prime_gt1/ is \lstinline/(prime $\mcbimplm{p}$)/ (i.e. the
type of \lstinline/prime_gt1/ were we substitute \mcbimpl{p} for
\lstinline/p/.  Unifying \lstinline/(prime $\mcbimplm{p}$)/ with
\lstinline/(prime q)/ is possible by assigning \lstinline/q/ to
\mcbimpl{p}.  Hence the proof term just constructed is
well typed, its type is \lstinline/(1 < q)/ and the place holder
has been set to be \lstinline{q}.
As we did for the identity function we can declare the \lstinline/p/
argument of \lstinline/prime_gt1/ as implicit.  \marginnote{maybe also
tell why one does not need two underscores in the last line}
Choosing a good  declaration of implicit arguments for lemmas is
tricky and requires one to think ahead how the lemma is used.
% section~\ref{sec:declaringimpl} is dedicated to that.

So far type inference and in particular unification has been used in
its simplest form, and indeed a first order unification algorithm
incapable of computing or synthesizing functions would have sufficed.
In the next section we introduce the encoding of the relations that
is at the base of the declarative programs we write to
extend unification in the higher order case.
As of today there is no precise, published, documentation of the type
inference and unification algorithms implemented in \Coq{}.  For a
technical presentation of a type inference algorithm close enough to
the one of \Coq{} we suggest the interested reader to
consult~\cite{DBLP:journals/corr/abs-1202-4905}.  The reader
interested in a technical presentation of a simplified version of the
unification algorithm implemented in \Coq{} can
read~\cite{unifcoq,betaderekjournal}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{records as relations, canonical base instances}
\mcbREQUIRE{}
\mcbPROVIDE{Canonical}
\mcbLEVEL{1}
\mcbNOTES{}
\mcbsection{Records as relations}\label{sec:eqtype}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In computes science a record is a very common data structure.  It is a
compound data type, a container with named fields.  Records are
represented faithfully in the \mcbCIC{} as
inductive data types with just one constructor holding all the data.
The peculiarity of the records we are going to use is that they are
dependently typed: the type of each field is allowed to depend on
the values of the fields that precedes it.

\Coq{} provides syntactic sugar for declaring record types.

\begin{coq}{name=eqtype}{}
Record eqType : Type := Pack {
  sort : Type;
  eq_op : sort -> sort -> bool
}.
\end{coq}
\label{eqtype:noproof}
\coqrun{name=eqtype1}{ssr,eqtype}

The sentence above declares a new inductive type called
\lstinline/eqType/ with one constructor named
\lstinline/Pack/ with two arguments.  The first one
is named \lstinline/sort/ and holds a type; the second and last
one is called \lstinline/eq_op/ and holds a comparison function
on terms of type \lstinline/sort/.  What this special syntax
does is declaring at once the following inductive type plus
a named projection for each record field:

\begin{coq}{name=eqtype2}{}
Inductive eqType : Type :=
  Pack sort of sort -> sort -> bool.
Definition sort (c : eqType) : Type :=
  let: Pack t _ := c in t.
Definition eq_op (c : eqType) : sort c -> sort c -> bool :=
  let: Pack _ f := c in f.
\end{coq}
\coqrun{name=eqtype2}{ssr,eqtype2}

Note that the type dependency between the two fields requires the first
projection to be used in order to define the type of the second projection.

We think of the \lstinline/eqType/ record type as a relation linking a
data type with a comparison function on that data type.  Before
putting the \lstinline/eqType/ relation to good use we declare an
inhabitant of such type, that we call an \emph{instance}, and we
examine a crucial property of the two projections just defined.

We relate the following comparison function with the \lstinline/nat/
data type: \marginnote{Maybe this function has been shown already}

\begin{coq}{name=eqn}{}
Fixpoint eqn m n {struct m} :=
  match m, n with
  | 0, 0 => true
  | m'.+1, n'.+1 => eqn m' n'
  | _, _ => false
  end.
Definition nat_eqType : eqType := @Pack nat eqn.
\end{coq}
\coqrun{name=eqn}{ssr,eqtype,eqn}

Projections, when applied to a record instance like
\lstinline/nat_eqType/ compute and extract the desired component.

\begin{coq}{name=redproj}{title=Computation of projections,width=6cm}
Eval simpl in sort nat_eqType.
Eval simpl in @eq_op nat_eqType.
\end{coq}
\coqrun{name=r}{ssr,eqtype,eqn,redproj}
\begin{coqout}{run=r}{title=Response,width=6cm}
= nat : Type
= eqn : sort nat_eqType ->
         sort nat_eqType -> bool
\end{coqout}

\marginnote{Maybe simpl is already explained?}
Given that \lstinline/(sort nat_eqType)/ and \lstinline/nat/
are convertible, equal up to computation, we can use the two terms
interchangeably.  The same holds for \lstinline/(eq_op nat_eqType)/
and \lstinline/eqn/.  Thanks to this fact \Coq{} can type check the
following term:

\begin{coq}{name=eqop}{width=5.7cm}
Check (@eq_op nat_eqType 3 4).
\end{coq}
\coqrun{name=e1}{ssr,eqtype,eqn,eqop}
\begin{coqout}{run=e1}{width=6.3cm}
eq_op 3 4 : bool
\end{coqout}

This term is well typed, but checking it is not as simple as one may
expect.
The \lstinline/eq_op/ function is applied to three arguments.
The first one is \lstinline/nat_eqType/ and its type,
\lstinline/eqType/, is trivially equal to the one expected by
\lstinline/eq_op/.
The following two arguments are hence expected of to be of type
\lstinline/(sort nat_eqType)/ but \lstinline/3/ and \lstinline/4/ are
of type \lstinline/nat/.
Recall that unification takes computation into account exactly as the
convertibility relation.  In this case the unification algorithm
unfolds the definition of \lstinline/nat_eqType/ obtaining
\lstinline/(sort (Pack nat eqn))/ and reduces the projection
extracting  \lstinline/nat/.  The obtained term literally matches the
type of the last two arguments given to \lstinline/eq_op/.

Now, why this complication?  Why should one prefer
\lstinline/(eq_op nat_eqType 3 4)/ to \lstinline/(eqn 3 4)/?
The answer is \emph{overloading}.
It is recurrent in mathematics and computer science to reuse
a symbol, a notation, in two different contexts.  A typical
example coming from the mathematical practice is to use the same
infix symbol $*$ to denote any ring multiplication.  A typical
computer science example is the use of the same infix
\lstinline/==/ symbol to denote the comparison over any data type.
Of course the underlying operation one intends to use depends on
the values it is applied to, or better their type.\footnote{
Actually the meaning of a symbol in math is even deeper: by writing $a
* b$ one expects the reader to figure out from the context which ring
we are talking about, recall its theory, and use this knowledge to
eventually justify the steps that follow in a proof.  This very
same approach let us also model this practice.  We will discuss
it in section~\ref{rec:itf}}
Using records lets us model these practices.
Note that, thanks to its higher order nature, the term \lstinline/eq_op/
can always be the head symbol denoting a comparison.  This makes
it possible to recognize, hence print, comparisons in a uniform way
as well as to input them.  On the contrary, in the simpler expression
\lstinline/(eqn 3 4)/ the name of the head symbol is very specific to
the type of the objects we are comparing.  Also note that
\marginnote{A bit too technical and boring}
polymorphism, in the sense of the \lstinline/ML/ programming language,
is not what we are looking for, since it would impose the comparison
function to behave uniformly on every type.  What we are looking
for is closer to the ad-hoc polymorphism of the \lstinline/Haskell/
programming language or the notion of subtyping provided by object
oriented languages.

In the rest of this chapter we focus on the overloading of the
\lstinline/==/ symbol and we start by defining another comparison
function, this time for the \lstinline/bool/ data type.

\begin{coq}{name=bety}{}
Definition eqb (a b : bool) := if a then b else ~~ b.
Definition bool_eqType : eqType := @Pack bool eqb.
\end{coq}

\marginnote{I need the reader to know something about Notation}
Now the idea is to define a notation that applies to any occurrence
of the \lstinline/eq_op/ head constant and use such
notation for both printing and parsing.

\begin{coqdef}{name=infix}
Notation "x == y" := (@eq_op _ x y).
\end{coqdef}
\begin{coqdef}{name=print}
Check (@eq_op bool_eqType true false).
Check (@eq_op nat_eqType 3 4).
\end{coqdef}
\begin{coq}{name=infix,print}{title=Overloaded notation,width=7cm}
Notation "x == y" := (@eq_op _ x y).
Check (@eq_op bool_eqType true false).
Check (@eq_op nat_eqType 3 4).
\end{coq}
\coqrun{name=r2}{ssr,eqtype,eqn,bety,infix,print}
\begin{coqout}{run=r2}{title=Response,width=5cm}

true == false : bool
3 == 4 : bool
\end{coqout}

As a printing rule, the place holder stands for a wild card: the
notation is used no matter the value of the first argument of
\lstinline/eq_op/.  As a result both occurrences of \lstinline/eq_op/,
line 2 and 3, are printed using the infix \lstinline/==/ syntax.
Of course the two operations are different, they are specific to the
type of the arguments and the typing discipline ensures the
arguments match the type of the comparison function packaged in
the record.

When the notation is used as a parsing rule, the place holder is
interpreted as an implicit argument: type inference is expected to find a value
for it.  Unfortunately such notation does not work as a parsing rule
yet.

\begin{coq}{name=parsenocs}{title=Error,width=6cm}
Check (3 == 4).
\end{coq}
\coqrun{name=nc;fail}{ssr,eqtype,eqn,infix,parsenocs}
\begin{coqout}{run=nc}{title=Response,width=6cm}
Error: The term "3" has type "nat" while it is expected to have type "sort ?e".
\end{coqout}

If we unravel the notation the input term is really
\lstinline/(eq_op _ 3 4)/. We name the place holder \mcbimpl{e}.
If we replay the type inference steps seen before, the unification
step is now failing.  Instead of \lstinline/(sort nat_eqType)/
versus \lstinline/nat/, now unification has to solve the problem
\lstinline/(sort $\mcbimplm{e}$)/ versus \lstinline/nat/.
This problem falls in one of the problematic classes we presented in
section~\ref{sec:hounif}: the system has to synthesize a comparison
function (or better a record instance containing a comparison
function).

\Coq{} gives up, leaving to the user the task of extending the
unification algorithm with a declarative program that is able to solve
unification problems of the form \lstinline/(sort $\mcbimplm{e}$)/
versus \lstinline/T/ for any \lstinline/T/.
Given the current context it seems reasonable to write an
extension that picks \lstinline/nat_eqType/ when \lstinline/T/ is
\lstinline/nat/ and \lstinline/bool_eqType/ when \lstinline/T/ is
\lstinline/bool/.  In the language of Canonical Structures such
program is expressed as follows.

\begin{coq}{name=declcs}{title=Declaring Canonical Structures}
Canonical nat_eqType.
Canonical bool_eqType.
\end{coq}

The keyword \lstinline/Canonical/ was chosen to stress that the
program is deterministic: each type  \lstinline/T/ is related to
(at most) one \emph{canonical} comparison function.

\begin{coq}{name=parse}{title=Testing CS Inference,width=6cm}
Check (3 == 4).
Check (true == false).
Eval compute in (3 == 4).
\end{coq}
\coqrun{name=cs}{ssr,eqtype,eqn,bety,infix,declcs,parse}
\begin{coqout}{run=cs}{title=Response,width=6cm}
3 == 4 : bool
true == false : bool
= false : bool
\end{coqout}

The mechanics of the small program we wrote using the
\lstinline/Canonical/ keyword can be explained using the
global table of canonical solutions.
Whenever a record instance is declared as canonical \Coq{}
adds to such table an entry for each field of the record type.

\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,width=8cm,center title,tabularx={ll|l},fonttitle=\sffamily\bfseries,title=Canonical Structures Index]
projection & value & solution \\ \hline
\lstinline/sort/ & \lstinline/nat/ & \lstinline/nat_eqType/  \\
\lstinline/sort/ & \lstinline/bool/ & \lstinline/bool_eqType/   \\
%\lstinline/eq_op/ & \lstinline/eqn/ & \lstinline/nat_eqType/  \\
%\lstinline/eq_op/ & \lstinline/eqb/ & \lstinline/bool_eqType/   \\
\hline
\end{tcolorbox}

Whenever a unification problem with the following shape is encountered,
the table of canonical solution is consulted.
\begin{center}
\lstinline/(projection $\mcbimplm{S}$)/ ~~versus~~ \lstinline/value/
\end{center}
The table is looked up using as keys the projection name and the
value.  The corresponding solution is assigned to the implicit
argument \mcbimpl{S}.

In the table we reported only the relevant entries.  Entries
corresponding to the \lstinline/eq_op/ projection play no role
and in the \mcbMC{} library the name of such projections is
usually omitted to signal that fact.

What makes this this approach interesting for a large library is that
record types can play the role of interfaces.  Once a record type has
been defined and some functionality associated to it, like a notation,
one can easily hook a new concept up by defining a corresponding
record instance and declaring it canonical.  One gets immediately all
the functionalities tied to such interface work on the new concept.
For example a user defining new data type with a comparison function
can immediately take advantage of the overloaded \lstinline/==/
notation by packing the type and the comparison function in an
\lstinline/eqType/ instance.

This pattern is so widespread and important that the \mcbMC{}
consistently uses the synonym keyword \lstinline/Structure/ in place of
\lstinline/Record/ in order to make record types playing the role
of interfaces easily recognizable.

Records are first class values in the \mcbCIC{}.  As we have seen
projections are no special, they are simple functions that pattern
match on an inductive data type to access the record fields.  Being
first class citizens means that one can write a term that combines
the fields of two records and builds a new record.  Thanks to this
fact the language of Canonical Structures is able to forge
new record instances by combining the existing ones via a set
of user definable combinators.  This is the subject of the next
section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{derived instances}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{RecCanonical}
\mcbLEVEL{1}
\mcbsection{Records as first class relations}\label{sec:receqtype}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

So far we have used the \lstinline/==/ symbol terms whose type is
atomic, like \lstinline/nat/ or \lstinline/bool/.  If we try for
example to use it on terms whose type was built using a type
constructor like the Cartesian product we encounter an error.

\begin{coq}{name=reccs}{title=Error,width=6cm}
Check (3, true) == (4, false).
$~$
\end{coq}
\coqrun{name=nc1;fail}{ssr,eqtype,eqn,bety,infix,declcs,reccs}
\begin{coqout}{run=nc1}{title=Response,width=6cm}
Error: The term "(3, true)" has type "(nat * bool)%type" while it is expected to have type "sort ?e".
\end{coqout}

The term \lstinline/(3,true)/ has type \lstinline/(nat * bool)/ and,
so far, we only taught \Coq{} how to compare booleans and natural
numbers, not how to compare pairs.
Intuitively the way to compare pairs is to compare their components
\emph{using the appropriate comparison function}.
Let's write a comparison function for pairs. \marginnote{Do we have
the Sections mechanism here?}

\begin{coq}{name=paircs}{title=Comparing pairs}
Definition prod_cmp eqA eqB x y :=
  @eq_op eqA x.1 y.1 && @eq_op eqB x.2 y.2.
\end{coq}

What is interesting about this comparison function is that the
pairs \lstinline/x/ and \lstinline/y/ are not allowed to have
an arbitrary, product, type here.  The typing constraints imposed
by the two \lstinline/eq_op/ occurrences forces the type of
\lstinline/x/ and \lstinline/y/ to be
\lstinline/(sort eqA * sort eqB)/.  This means
that the records \lstinline/eqA/ and \lstinline/eqB/ hold
a sensible comparison function for, respectively, terms of
type \lstinline/(sort eqA)/ and \lstinline/(sort eqB)/.

It is now sufficient to pack together the Cartesian product type
constructor and this comparison function in an \lstinline/eqType/
instance to extend the canonical structures inference machinery
with a new combinator.

\begin{coq}{name=declcs2}{title=Recursive canonical structure}
Definition prod_eqType (eqA eqB : eqType) : eqType :=
  @Pack (sort eqA * sort eqB) (@prod_cmp eqA eqB).
Canonical prod_eqType.
\end{coq}

The global table of canonical solutions is extended as follows.

\noindent
\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,center title,tabularx={ll|l|l},fonttitle=\sffamily\bfseries,title=Canonical Structures Index]
projection & value & solution & combines solutions for \\ \hline
\lstinline/sort/ & \lstinline/nat/ & \lstinline/nat_eqType/ & \\
\lstinline/sort/ & \lstinline/bool/ & \lstinline/bool_eqType/ &  \\
\lstinline/sort/ & \lstinline/T1 * T2/ & \lstinline/prod_eqType pA pB/
	& \lstinline/pA/ $\leftarrow$ (\lstinline/sort/,\lstinline/T1/),
	  \lstinline/pB/ $\leftarrow$ (\lstinline/sort/,\lstinline/T2/)\\
\hline
\end{tcolorbox}

The third column is empty for base instances while it contains
the recursive calls for instance combinators.  With the updated
table when the unification problem
\begin{center}
\lstinline/(sort $\mcbimplm{e}$)/ ~~versus~~ \lstinline/(T1 * T2)/
\end{center}
is encountered a solution for \mcbimpl{e} is found by proceeding
in the following way.  Two new unification problems are generated:
\lstinline/(sort $\mcbimplm{eqA}$)/ versus \lstinline/T1/ and
\lstinline/(sort $\mcbimplm{eqB}$)/ versus \lstinline/T2/.  If both
are successful and \lstinline/v1/ is the solution for
\mcbimpl{eqA} and \lstinline/v2/ for \mcbimpl{eqB}, the solution for
\mcbimpl{e} is \lstinline/(prod_eqType v1 v2)/.

After the table of canonical solutions has been extended our example
is accepted.\marginnote{no idea if that output can be
produce by \Coq{}}

\begin{coq}{name=parsecs2}{title=Example,width=6.3cm}
Check (3, true) == (4, false).
\end{coq}
\coqrun{name=cs2}{ssr,eqtype,eqn,bety,infix,declcs,paircs,declcs2,parsecs2}
\begin{coqout}{run=cs2}{title=Response,width=5.7cm}
(3, true) == (4, false) : bool
\end{coqout}

The term synthesized by \Coq{} is the folowing one:

\begin{coq}{name=parsecs3}{}
   @eq_op (prod_eqType nat_eqType bool_eqType) (3, true) (4, false).
\end{coq}
\coqrun{name=cs3}{ssr,eqtype,eqn,bety,infix,declcs,paircs,declcs2,parsecs3}

\marginnote{
Make other examples? Other overloaded stuff: maybe and example of
how to hook up to infix in ? or locked? or whatever?
In any case a table with ``all'' the interfaces should probably be
part of the book
}

In the running example of this chapter we use the canonical structures
language to express structurally recursive programs on the syntax
of types.  The \mcbCIC{} allows arbitrary terms to occur inside
types.  As a consequence the language of canonical structures can
express also structurally recursive programs on the syntax
of terms.  This capability is used, for example, in
section~\ref{sec:bigoplemmas} to related Monoid laws to function
symbols to model the syntax and theory of iterated, ``big'', operators.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEVEL{1}
\mcbREQUIRE{records + CS}
\mcbPROVIDE{eqType}
\mcbLEARN{interface to a theory}
\mcbsection{Records as (first class) interfaces}\label{rec:itf}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When we define an overloaded notation we convoy
trough it more than just the arity (or the type) of the associated
operation.  We associate to it a property, or a collection thereof.
For example, in the context of group theory, the infix \C{+} symbol
is typically preferred to \C{*} whenever the group law is
commutative.

Going back to our running example, the actual definition of \lstinline/eqType/
used in the \mcbMC{} library also contains a property.
Indeed there is little one can do with a comparison function if that
function is not ``correct''.

\begin{coq}{name=eqtype}{title=eqType}
Module Equality.

Structure type : Type := Pack {
  sort : Type;
  op : sort -> sort -> bool;
  axiom : forall x y, reflect (x = y) (eq_op x y)
}.

End Equality.
\end{coq}

The extra property turns the
\lstinline/eqType/ relation into a proper \emph{interface},
that fully specifies what \C{op} is.

The axiom says that the boolean comparison function
is compatible with equality: two ground terms compare as equal if and
only if they are syntactically equal.  Note that this means that the
comparison function is not allowed to quotient the type by identifying
two syntactically different terms.

\mantra{The infix notation \lstinline/==/ stands for
a comparison function compatible with Leibnitz equality
(substitution in any context)}

The \C{Equality} module enclosing the record acts a name space:
\C{type}, \C{sort},
\C{eq} and \C{axiom}, three very generic words, are here
made local to the \C{Equality} name space becoming, respectively,
\C{Equality.type}, \C{Equality.sort}, \C{Equality.op} and \C{Equality.axiom}.

As in section~\ref{sec:eqtype}, the record plays the role of
a relation and its \C{sort} component is again the only field
that drives canonical structure inference. Following
a terminology typical of object oriented programming languages,
the set of operations (and properties) that define an interface is
called a \emph{class}.  In the next chapter we are going to re-use already
defined classes in order to build new ones by mixing-in additional
properties (typically called axioms).
Hence the definition of \C{eqType} in the
\mcbMC{} library is closer to the following one:
\marginnote{We assume that \C{rel} is a known concept here}

\begin{coq}{name=eqtype}{title=The real definition of eqType}
Module Equality.

Definition axiom T (e : rel T) := forall x y, reflect (x = y) (e x y).

Record mixin_of T := Mixin {op : rel T; _ : axiom op}.
Notation class_of := mixin_of.

Structure type : Type := Pack {sort :> Type; class : class_of sort; }.

End Equality.

Notation eqType := Equality.type.
Definition eq_op T := Equality.op (Equality.class T).
Notation "x == y" := (@eq_op _ x y).
\end{coq}

In this simple case there is only one property, named
\C{Equality.axiom}, and the class is exactly the mixin.

Said that, nothing really changes: the \C{eqType} structure
relates a type with a signature.

Remark the use of \C{:>} instead of \C{:} to type the
field called \C{sort}.  This tells \Coq{} to declare the
\C{Equality.sort} projection
as a coercion, enabling one to write \C{(forall T : eqType, forall x y
: T, P)}.  Ineed \C{T} is not a type, only its \C{sort} projection is.
\gotcha{being \C{Equality.sort} a coercion, it is not displayed by
\Coq{}, hence error messages about a missing canonical structure
declaration typically look very confusing: has type nat but should
have type ?e}

Given the new definition of \lstinline/eqType/,
when we write \lstinline/(a == b)/ type inference does not only infer
a function to compare \lstinline/a/ with \lstinline/b/ but also a
proof that such function is correct.
Indeed declaring the \C{eqType} instance for \C{nat} requires some
extra work, namely proving the correctness of the \C{eqn} function.

\begin{coq}{name=eqtype}{title=The complete definition of nat\_eqType}
Lemma eqnP : Equality.axiom eqn.
Proof.
move=> n m; apply: (iffP idP) => [|<-]; last by elim n.
by elim: n m => [|n IHn] [|m] //= /IHn->.
Qed.
\end{coq}

We now have all the pieces to declare \C{eqn} as canonical.

\begin{coq}{name=eqtype}{title=Making eqn canonical}
Definition nat_eqMixin := Equality.Mixin eqnP.
Canonical nat_eqType := @Equality.Pack nat nat_eqMixin.
\end{coq}

Note that the \C{Canonical} declaration is expanded (showing the
otherwise implicit first argument of \C{Pack}) to document that
we are relating the type \C{nat} with its comparison operation.
\marginnote{This is not exactly as in the .v files, but is way closer
and should ease section 6 (hierarchy)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{overloaded lemmas}
\mcbREQUIRE{}
\mcbPROVIDE{eqP}
\mcbLEVEL{1}
\mcbsection{Using a generic theory}\label{sec:eqtypetheory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The whole point of defining interfaces is to share a theory
among all examples of each interface.
In other words a theory proved starting from the
properties (axioms) of an interface applies to all its instances,
transparently.  Every lemma part of an abstract theory
is \emph{generic}: the very same name can be used for each and every
instance of the interface, exactly as the \C{==} notation.

The simplest lemma part of the theory of \C{eqType} is the
\lstinline/eqP/ generic lemma that can be used in conjunction with
any occurrence of the \lstinline/==/ notation.
\index[coq]{\C{eqP}}

\begin{coq}{name=eqP}{title=The eqP lemma}
Lemma eqP (T : eqType) : Equality.axiom (@Equality.op T).
Proof. by case: T => ty [op prop]; exact: prop. Qed.
\end{coq}

The proof is just unpacking the input \lstinline/T/.
We can use it on an concrete example of \C{eqType} like \C{nat}

\begin{coq}{name=test}{title=Use of eqP}
Lemma test (x y : nat) : x == y -> x + y == y + y.
Proof. by move=> /eqP def_x; rewrite def_x. Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}

In short, \C{eqP} can be used to change view: turn any
\C{==} into \C{=} and viceversa.

The \C{eqP} lemma also applies to abstract instances of \C{eqType}.
When we rework the instance of the type \C{(T1 * T2)} we see that the
proof, by means of the \C{eqP} lemma, uses the axiom of \C{T1} and
\C{T2}.

\begin{coq}{name=eqtype}{title=The complete definition of prod\_eqType}
Section ProdEqType.
Variable T1 T2 : eqType.

Definition pair_eq := [rel u v : T1 * T2 | (u.1 == v.1) && (u.2 == v.2)].

Lemma pair_eqP : Equality.axiom pair_eq.
Proof.
move=> [x1 x2] [y1 y2] /=; apply: (iffP andP) => [[]|[<- <-]] //=.
by move/eqP->; move/eqP->.
Qed.

Definition prod_eqMixin := Equality.Mixin pair_eqP.
Canonical prod_eqType := @Equality.Pack (T1 * T2) prod_eqMixin.
End ProdEqType.
\end{coq}

Like for \C{nat} the generic lemma \C{eqP} applies to
any \C{eqType} instance, like \C{(bool * nat)}

\begin{coq}{name=test}{title=Use of eqP}
Lemma test (x y : nat) (a b : bool) : (a,x) == (b,y) -> fst (a,x) == b.
Proof. by move/eqP=> def_ax; rewrite def_ax. Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}

The \lstinline/(a,x)$~$== (b,y)/ assumption is reflected to
\lstinline/(a,x)$~$= (b,y)/ by using the \lstinline/eqP/ view
specified by the user.  Here we write \lstinline/==/ to have
all the benefits of a computable function (simplification, reasoning
by cases), but when we need the underlying logical property of
substitutivity we access it via the view \lstinline/eqP/.

\begin{coq}{name=test}{title=Why one should always use \C{==}
	(computation)}
Lemma test (x y : nat) : (true,x) == (false,y) -> false.
Proof. by []. Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}

This is true (or better, the hypothesis is false) by computation.

\begin{coq}{name=test}{title=Why one should always use \C{==} (EM)}
Lemma test (x y : nat) : if x == y.+1 then x != 0 else true.
Proof. by case E: (x == y.+1) => //; rewrite (eqP E). Qed.
\end{coq}
\coqrun{name=r7}{ssr,eqtype,eqP}
\coqrun{name=r8}{ssr,test}


\marginnote{Maybe here suggest to use ifP and =P if not already known, or
do it now}

\mantra{
	whenever we want to state equality between two expressions, if
	they live in an eq type, always use \lstinline/==/.
}


Note that the proof language silently adjusted the view
using \lstinline/elimT/.

\begin{coq}{name=elimt}{title=The eqtype view,width=5.3cm}
Check elimT.

\end{coq}
\coqrun{name=et}{ssr,elimt}
\begin{coqout}{run=et}{title=Response,width=6.7cm}
elimT : forall (P : Prop) (b : bool),
          reflect P b -> b -> P
\end{coqout}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{eqType is the base of (abstract) ssr style}
\mcbREQUIRE{}
\mcbPROVIDE{\\in}
\mcbLEVEL{1}
\mcbsection{The generic theory of sequences}\label{sec:seqtypetheory}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Now that the \lstinline/eqType/ interface equips a type with a well
specified comparison function we can use it build abstract theories,
for example the one of sequences.

It is worth to remark that the concept of interface is crucial to
the development of such theory.  If we try to develop the theory
of the type \C{(seq T)} for an arbitrary \C{T}, we can't go much far.
For example we can express what belonging to a sequence means, but
not write a program that tests if a value is indeed in the list.  As a
consequence we lose the form automation provided by computation
and it also becomes harder to reason by cases on the membership predicate.
On the contrary when we quantify a theory on the type  \C{(seq T)} for a
\C{T} that is an \C{eqType}, we recover all that.  In other words
by better specifying the type that parametrizes a generic container
we define which operations are lecit and which properties hold.
So far the only interface we know is \C{eqType}, that is very
connected with the ``small scale reflection'' approach we follow.
In the next chapters more elaborate interface will enable us to
organize knowledge in a more articulated way.

Going back to the abstract theory of sequences over an \C{eqType},
we start by defining the membership operation.

\begin{coq}{name=memseq}{title=Membership}
Section SeqTheory.
Variable T : eqType.
Implicit Type s : seq T.

Fixpoint mem_seq s x :=
  if s is y :: s' then (y == x) && mem_seq s' x else false.
\end{coq}
\coqrun{name=memseq}{ssr,memseq}

Like we did for the overloaded \C{==} notation, we can define the
\C{\\in} (and \C{\\notin}) infix notation.  We can then easily
define what a duplicate-free sequence is, and how to enforce such
property.

\begin{coq}{name=uniq}{}
Fixpoint uniq s :=
  if s is x :: s' then (x \notin s') && uniq s' else true.
Fixpoint undup s :=
  if s is x :: s' then
    if x \in s' then undup s' else x :: undup s'
  else [::].
\end{coq}
\coqrun{name=uniq}{ssr,uniq}

Proofs about such concepts can be made pretty much as if
the type \C{T} was \C{nat} or \C{bool}, i.e. our predicates do
compute.
\marginnote{requires \C{=i}}

\begin{coq}{name=undupuniq1}{title=\C{undup} is correct (step 1)}
Lemma in_cons y s x : (x \in y :: s) = (x == y) || (x \in s).
Proof. by []. Qed.

Lemma mem_undup s : undup s =i s.
Proof.
move=> x; elim: s => //= y s IHs.
case Hy: (y \in s); last by rewrite in_cons IHs.
by rewrite in_cons IHs; case: eqP => // ->.
Qed.
\end{coq}

The \C{in\_cons} lemma is just a convenience rewrite rule, while
\C{mem\_undup} says that the \C{undup} function does not drop
any non-duplicate element.  Note that in the proof we use both
decidability of membership (\C{Hy}) and then the decidability of
equality (via \C{eqP}).

\begin{coq}{name=undupuniq2}{title=\C{undup} is correct (setp 2)}
Lemma undup_uniq s : uniq (undup s).
Proof.
by elim: s => //= x s IHs; case sx: (x \in s); rewrite //= mem_undup sx.
Qed.
\end{coq}
\coqrun{name=uniqp}{ssr,uniq,undupuniq1,undupuniq2,abort}

The proof of \c{undup\_uniq} requires not new ingredients and
completes the specification of \C{undup}.

A last, very important, step in the theory of sequences is to show
that the container preserves the \C{eqType} interface: whenever we can
compare the elements of a sequence, we can also compare sequences.

\begin{coq}{name=seqeqtype}{title=\C{eqType} for sequences}
Fixpoint eqseq s1 s2 {struct s2} :=
  match s1, s2 with
  | [::], [::] => true
  | x1 :: s1', x2 :: s2' => (x1 == x2) && eqseq s1' s2'
  | _, _ => false
  end.

Lemma eqseqP : Equality.axiom eqseq.
Proof.
elim=> [|x1 s1 IHs] [|x2 s2] /=; do? [exact: ReflectT | exact: ReflectF].
case: (x1 =P x2) => [<-|neqx]; last by apply: ReflectF => -[eqx _].
by apply: (iffP (IHs s2)) => [<-|[]].
Qed.

Definition seq_eqMixin := Equality.Mixin eqseqP.
Canonical seq_eqType := @Equality.Pack (seq T) seq_eqMixin.
\end{coq}

As an example we build a sequence of sequences, and we assert that
we can use the \C{==} and \C{\\in} notation on it, as well as apply
the list operations and theorems on objects of type \C{(seq (seq T))}
when \C{T} is an \C{eqType}.

\begin{coq}{name=itereqtype}{}
Let s1 := [:: 1; 2 ].
Let s2 := [:: 3; 5; 7].
Let ss :  seq (seq nat) := [:: s1 ; s2 ].
Check (ss != [::]) && s1 \in ss && undup_uniq ss.
\end{coq}
\coqrun{name=uniqp2}{ssr,itereqtype}

As we have anticipated in Chapter 1, functional programming and lists
can model, definite, iterated operations like the ``big'' sum
$\Sigma$.  Next Section describes how the generic theory
of iterated operations can be built and made practical thanks again
to the programming of type inference via the canonical structures
language.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{bigop}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{overloaded big notations}
\mcbLEVEL{1}
\mcbsection{The generic theory of ``big'' operators}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The objective of the \emph{bigop} library is to provide compact notations 
for definite iterated operations and a library of general results about them.

Lets take two examples of iterated operations:

$$
\sum_{i=1}^n f(i) = f(1) + f(2) + \ldots + f(n)
\qquad \bigcup_{a \in A} g(a) = g(a_1) \cup g(a_2) \cup \ldots \cup g(a_{|A|})
$$

To share an infrastructure for this class of operators we have to
identify a common pattern.  First the big symbol in front specifies the
operation begin iterated and the neutral element for such operator.
For example if $A$ is empty, then the union of all $g(a)$ is $\emptyset$
while if $n=0$ then the sum of all $f(i)$ is $0$.
Then the range is an expression identifying a finite set of elements,
some times expressing an order (relevant when the iterated operation is not
commutative).  Finally a general term describing the
items being combined by the iterated operation.

As already mentioned in Chapter 1, %~\ref{sec:bigopnat}, 
the functional programming language
provided by \Coq{} can express in a very natural way iterations over
a finite domain.  In particular such finite domain can be represented
as a list; the general term $f(i)$ by a function \C{(fun i =>
...)}; the operation of evaluating a function on all the
elements of list and combining the results by the \C{foldr} operator.

Funtional programming can also be used to describe the finite domain.
For example the list of natural numbers $m, m+1, \ldots, m + (n-m)$ 
corresponding to the range $m \leq i < n$ can be built using the \C{iota}
function as follows:
\begin{coq}{name=iota}{}
Definition index_iota m n := iota m (n - m).
\end{coq}

The only component of typical notations for iterated operations we have not
discussed yet is the filter, used to iterate the operation only on a
subset of the domain.
For example to state that the sum of the first $n$ odd numbers is $n^2$ 
one could write:
$$
\sum_{i < 2n,\, 2 \nmid i} i = n^2
$$
An alternative writing for the same summation exploits the general
terms to rule out even numbers:
$$
\sum_{i < n} (i * 2 - 1) = n^2
$$
While this latter writing is elegant, it is harder to support
generically, since the filtering condition is not explicit.
For example the following equation clearly holds for any filter,
range and general term.  It would be hard to express such statement
if the filter was mixed with the general term, and hence its
negation was not obvious to formulate.
$$
\sum_{i < 2n,\,  2 \mid i} i \;+ \sum_{i < 2n,\,  2 \nmid i}  i = \sum_{i < 2n} i
$$

Last, not all filtering conditions can be naturally expressed in the
general term. En example is not being a prime number.

At the light of that our formal statement concerning the sum
of odd numbers is the following:

\begin{coq}{name=bigop21}{}
Lemma sum_odd n : \sum_(0 <= i < n.*2 | odd i) i = n^2.
\end{coq}

Under the hood we expect to find the following expression:

\begin{coq}{name=bigop2}{}
Lemma sum_odd n :
  foldr (fun acc i => if odd i then i + acc else acc)
    0 (index_iota 0 n.*2)
  = n^2
\end{coq}

The following Section details how the generic notation for
iterated operation is built and specialized to frequent operations
like $\Sigma$.  section~\ref{sec:bigoplemmas} focuses on
the generic theory for iterated operations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The generic notation for \C{foldr}}

The generic notation for iterated operations has to be attached to
something more specific than \C{foldr} in order to clearly identify
all components

\begin{coq}{name=bigop2}{}
Definition bigop R I idx op r (P : pred I) (F : I -> R) : R :=
  foldr (fun i x => if P i then op (F i) x else x) idx r.
\end{coq}

Using the \C{bigop} contant to express our statement leads to

\begin{coq}{name=bigop2}{}
Lemma sum_odd n :
  bigop 0 addn (index_iota 0 n.*2) odd (fun i => i) = n^2
\end{coq}

Note that \C{odd} is already a predicate on \C{nat}, the general
term is the identity function, the range \C{r} is \C{(index_iota 0
n.*2)}, the iterated operation \C{addn} and the initial value is
\C{0}.

A generic notation can now be attached to \C{bigop}.

\begin{coq}{name=bigopnotation}{}
Notation "\big [ op / idx ]_ ( i <- r | P ) F" :=
  (bigop idx op r (fun i => P%B) (fun i => F)) : big_scope.
\end{coq}

Here \C{op} is the iterated operation, \C{idx} the neutral element
\C{r} the range, \C{P} the filter (hence the boolean scope)
and \C{F} the general term.  Using such notation the running example
can be states as follows.

\begin{coq}{name=bigop21}{}
Lemma sum_odd n : \big[addn/0]_(i <- index_iota 0 n.*2 | odd i) i = n^2.
\end{coq}

To obtain a notation closer to the mathematical one we can specialize
at once the iterated operation and the neutral element as follows.

\begin{coq}{name=bigop3nat}{}
Local Notation "+%N" := addn (at level 0, only parsing).
Notation "\sum_ ( i <- r | P ) F" :=
  (\big[+%N/0%N]_(i <- r | P%B) F%N) : nat_scope.
\end{coq}

Such notation is placed in \C{nat\_scope} and is indeed specialized
on \C{addn} and \C{0}.  The general term \C{F} is also placed in
the scope of natural numbers.
We can proceed even furhter and specialize the notation to
a numerical range:

\begin{coq}{name=bigop3nat2}{}
Notation "\big [ op / idx ]_ ( m <= i < n | P ) F" :=
  (bigop idx op (index_iota m n) (fun i : nat => P%B) (fun i => F))
     : big_scope.
Notation "\sum_ ( m <= i < n ) F" :=
  (\big[+%N/0%N]_(m <= i < n) F%N) : nat_scope.
\end{coq}
\coqrun{name=uniqp2}{ssr,bigop,bigop2}

We can now comfortably state the theorem about the sum of odd numbers
inside \C{nat\_scope}.  The proof of this lemma is left as an
exercise; we now focus on a simpler instance, for $n$ equal to $3$, to
introduce the library that equips iterated operations.

\begin{coq}{name=bigop3ex}{}
Lemma sum_odd_3 : \sum_(0 <= i < 3.*2 | odd i) i = 3^2.
Proof.
rewrite unlock /=.
\end{coq}

The \C{bigop} constant is ``locked'' to make the notation steady.  To
unravel its computational behavior one has to rewrite with \C{unlock}.

\begin{coqout}{}{}
============================
1 + (3 + (5 + 0)) = 3^2
\end{coqout}

The computation behavior of \C{bigop} is generic, it does not
depend on the iterated operation.
On the contrary some results
on iterated operations may depend on a particular property of the
operation. For example to pull out the last item from the summation,
i.e. using the following lemma


$$
\mbox{if }a \le b\mbox{ then }\sum_{a \le i < b+1} F i = \sum_{a \le i < b} F i + F b
$$

to obtain

\begin{coqout}{}{}
============================
1 + (3 + 0) + 5 = 3^2
\end{coqout}

one really needs the iterated operation, addition here, 
to be associative.  Also note
that, given the filter, what one really pulls out is
\C{(if odd 5 then 5 else 0)}, so for the theorem to be true for any
range, \C{0} must also be neutral.

The lemma to pull out the last item of an iterated operation
is provided as the combination of two simlper lemmas called
respectively \C{big\_nat\_recr} and \C{big\_mkcond}.

The former states that one can pull out of an interated operation on a
numerical range the last element, proviso the range is non empty.

\begin{coq}{name=bigop3natrec}{}
Lemma big_nat_recr n m F : m <= n ->
  \big[*%M/1]_(m <= i < n.+1) F i = (\big[*%M/1]_(m <= i < n) F i) * F n.
\end{coq}

Such lemma  applies to any operation \C{*\%M} and any neutral element
\C{1} and any generic term \C{F}, while the filter \C{P} is
fixed to \C{true} (i.e. no filter).  The \C{big\_mkcond} lemmas
moves the filter into the generic term.

\begin{coq}{name=bigop3mkcond}{}
Lemma big_mkcond I r (P : pred I) F :
  \big[*%M/1]_(i <- r | P i) F i =
     \big[*%M/1]_(i <- r) (if P i then F i else 1).
\end{coq}

If we chain the two lemmas we can pull out the last item.

\begin{coq}{name=bigop3natrec}{}
Lemma sum_odd_3 : 
  \sum_(1 <= i < 3.*2) i.*2 = 5 * 4
Proof.
rewrite big_mkcond big_nat_recr //=.
rewrite unlock /=.
\end{coq}
\begin{coqout}{}{}
============================
\sum_(0 <= i < 5) (if odd i then i else 0) + 5 = 3^2
\end{coqout}

When the last item is pulled out we can unlock the computation
and obtain the following goal:

\begin{coqout}{}{}
============================
0 + (1 + (0 + (3 + (0 + 0)))) + 5 = 3^2
\end{coqout}

It is clear that for the two lemmas to be provable
one needs the associativiy property of \C{addn} and also that
\C{0} is neutral.
In other words the lemmas we used require the operation \C{*\%M} to form
a monoid together with the unit \C{1}.

We detail how this requirement is stated, and automatically satisfied by
\Coq{} in the case of \C{addn}, in the next Section.  We conclude this
Section by showing that the same lemmas also apply to an iterated
product.

\begin{coq}{name=bigop3natrec}{width=5.5cm}
Lemma prod_fact_4 : 
  \prod_(1 <= i < 5) i = 4`!.
Proof.
rewrite big_nat_recr //=.
\end{coq}
\begin{coqout}{}{width=6cm,title=Pulling out the last product}
============================
\prod_(1 <= i < 4) i * 4 = 4`!
\end{coqout}

This is the reason why we can say that the bigop library is generic:
it works uniformly on any iterated operator, and provided the operator
has certain properties it give uniform access to a palette of lemmas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Assumptions of a bigop lemma}\label{sec:bigoplemmas}

As we anticipated, canonical structures can be indexed not only on
types, but on any term.  In particular we can index them on function
symbols to relate, for example, \C{addn} and its monoid structure.

Here we only present the \C{Monoid} interface an operation has to
satisfy in order access a class of generic lemmas.
chapter~\ref{ch:hierarchy} adds other interfaces to the picture and organizes
the bigop library around them.

\begin{coq}{name=bigop}{}
Module Monoid.
Section Definitions.
Variables (T : Type) (idm : T).

Structure law := Law {
  operator : T -> T -> T;
  _ : associative operator;
  _ : left_id idm operator;
  _ : right_id idm operator
}.
\end{coq}
\coqrun{name=uniqp2}{ssr,bigop}

The \C{Monoid.law} structure relates the \C{operator} (the key used by
canonical structures) to the three propoerties of monois.

We can then parametrize an intire theory on this interface.

\begin{coq}{name=bigop1}{}
Coercion operator : law >-> Funclass.
Section MonoidProperties.
Variable R : Type.

Variable idx : R.
Notation Local "1" := idx.

Variable op : Monoid.law idx.
Notation Local "*%M" := op (at level 0).
Notation Local "x * y" := (op x y).
\end{coq}

The lemma we used in the previous section, \C{big\_nat\_recr}, is
stated as follows. Note that
\C{op} is a record, and not a function, but since the \C{operator}
projection is declared as a coercion we can use \C{op} as such.
In particular under the hood of the expression \C{\\big[*\%M/1]} we
find \C{\\big[ operation op / idx ]}.


\begin{coq}{name=bigop1}{}
Lemma big_nat_recr n m F : m <= n ->
  \big[*%M/1]_(m <= i < n.+1) F i = (\big[*%M/1]_(m <= i < n) F i) * F n.
\end{coq}
\coqrun{name=uniqp2}{ssr,bigop}

If we print such statement once the \C{Section MonoidProperties} is
closed we see the requirement affecting the operation \C{op} explicitly.

\begin{coqout}{}{}
big_nat_recr :
  forall (R : Type) (idx : R) (op : Monoid.law idx) (n m : nat) (F : nat -> R),
  m <= n ->
    \big[op/idx]_(m <= i < n.+1) F i =
    op (\big[op/idx]_(m <= i < n) F i) (F n)
\end{coqout}

Note that wherever the operation \C{op} occurs we also find
the \C{Monoid.operation} projection.

To make this lemma available on the addition on natural numbers
we need to declare the canonical monoid structure on \C{addn}.

\begin{coq}{name=natmonoid}{}
Canonical addn_monoid := Monoid.Law addnA add0n addn0.
\end{coq}

This command adds the following rules to the canonical structures
index:

\noindent
\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,width=8cm,center title,tabularx={ll|l},fonttitle=\sffamily\bfseries,title=Canonical Structures Index]
projection & value & solution \\ \hline
\lstinline/Monoid.operator/ & \lstinline/addn/ & \lstinline/addn_monoid/  \\
\hline
\end{tcolorbox}

Whenever the lemma is applied to an expression about natural numbers
as

\begin{coq}{name=bigop2}{}
Lemma test : \sum_(0 <= i < 6) i =  \sum_(0 <= i < 5) i + 5.
Proof. by apply: big_nat_recr. Qed.
\end{coq}

the following unification problem has to be solved:
\C{(BigBody i addn true i)} versus \C{(BigBody i (operator ?m) (?P i) (?F i))}.
The sub problem \C{addn} versus \C{(operator ?m)} is solved by
canonical structure inference.  Inferring a value for \C{?m} mean
inferring a proof that \C{addn} forms a monoid with \C{0}: a
prerequisite for the \C{big\_nat\_recr} lemma we don't have to provide
by hand.

% The problem \C{i} versus \C{(?F i)}
% is a hard problem too, since \C{?F} is a program, but it has
% a unique solution: being \C{i} a locally boud variable, not in the
% scope of the body of \C{?F}, the only way for \C{(?F i)} to
% produce \C{i} is to return its input.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEVEL{1}
\mcbsubsection{Searching the bigop library}

Searching the bigop library for a lemm is slightly harder than
searching the other libraries as explained in~\ref{sec:search}.
In particular one can hardly search with patterns.  For example
the following searches returns no results:

\begin{coq}{}{}
Search _ (\sum_(0 <= i < 0) _).
\end{coq}
A lemma stating that an empty sum is zero is not part of the library.
What is part of the library is a lemma that says that if the list
begin folded is \C{nil} then the result is the initial value.  Such
lemma, called \C{big_nil}, indeed mentions only \C{[::]} in its
statement, and not the (logically) equivalent \C{(index_iota 0 0)}.
Still the goal \C{(\\sum_(0 <= i < 0) i = 0)} can be solved by
\C{big_nil}.  Finally, the pattern we provide specifies a trivial
filter, while the lemma is true for any filtering predicate.
Of course one can craft a pattern that finds such lemma, but it is very
verbose and hence inconvenient.

\begin{coq}{}{}
Search _ (\big[_/_]_(i <- [::] | _) _).
\end{coq}

The recommended way to search the library is by name, using the word
``big''.  For example to find all lemmas allowing one to prove the
equality of two iterated operators one can\C{ Search "eq" "big"}.
Similarly, induction lemmas can be found with\C{ Search "ind"
"big"};  index exchange lemmas with\C{ Search "exchange" "big"};
lemmas pulling out elements from the iteration
with\C{ Search "rec" "big"}; lemmas  working on the filter condition
with\C{ Search "cond" "big"}, etc\ldots


Finally the \mcbMC{} user is advised to read the contents of the
\C{bigop.v} file in order get acquainted with the nameing policy used
in that library.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Real bigop notation}
\mcbREQUIRE{bigop}
\mcbPROVIDE{BigBody}
\mcbLEVEL{3}
\mcbsection{Stable notations for big operators}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The definition of \C{bigop} and the notations attached to it
are defined in a more complex way in the \mcbMC{} library.
In particular \C{bigop} is fragile because the predicate and
the general term do not share the same binder.  For example,
if we write the following

\begin{coq}{name=bigop2}{}
Lemma sum_odd n :
  bigop 0 addn (index_iota 0 n.*2) (fun j => odd j) (fun i => i) = n^2
\end{coq}

What should be printed by the system?  It is an iterated sum on
\C{j} or \C{i}?  Similarly, if the index becomes unused during a
proof, which name should be printed?

\begin{coq}{name=bigop2}{}
Lemma sum_0 n :
  bigop 0 addn (index_iota 0 n) (fun _ => true) (fun _ => 0) = 0
\end{coq}

To solve these problems we craft a box, \C{BigBody}, with
separate compartments for each sub component.  Such box will
be used under a single binder and will hold an occurrence of the
bound variable even if it is unused in the predicate and in the
general term.

\begin{coq}{name=bigop2}{}
Inductive bigbody R I := BigBody of I & (R -> R -> R) & bool & R.
\end{coq}

The arguments of \C{BigBody} are respectively the index, the
iterated operation, the filter and the generic expression.
For our running example the \C{bigbody} component would be:

\begin{coq}{name=bigopeven}{}
Definition sum_odd_def_body i := BigBody i addn (odd i) i.
\end{coq}

It is then easy to turn such compound term into the function expected
by \C{foldr}:

\begin{coq}{name=bigopapplybig}{}
Definition applybig {R I} (body : bigbody R I) acc :=
  let: BigBody _ op b v := body in if b then op v acc else acc.
\end{coq}

Finally the generic iterated operator can be defined as follows.

\begin{coq}{name=bigop3}{}
Definition bigop R I idx r (body : I -> bigbody R I) :=
  foldr (applybig \o body) idx r.
\end{coq}

And a generic notation can be attached to it.

\begin{coq}{name=bigopnotation}{}
Notation "\big [ op / idx ]_ ( i <- r | P ) F" :=
  (bigop idx r (fun i => BigBody i op P%B F)) : big_scope.
\end{coq}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Declaring overloaded notations}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{Notation}
\mcbLEVEL{2}
\mcbsection{Working with overloaded notations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This little section deals with two ``technological issues'' the reader
may need to know in order to define overloaded notations or work
comfortably with them.

The first one is the necessity to tune the behavior of the
simplification tactic (the \C{/=} switch) to avoid loosing the
head constant to which the overloaded notation is attached.
For example the following term:

\begin{coq}{name=infix,print}{}
  (@eq_op bool_eqType true false).
\end{coq}

can be simplifies (reduced) to the following one

\begin{coq}{name=infix,print}{}
  (@eqb true false).
\end{coq}

While the two terms are logically equivalent (i.e. the logic cannot
distinguish them) the pretty printer can.  Indeed the overloaded
\C{==} notation is attached to the \C{eq\_op} constant, and if such
constant fades away the notation follows it.  \Coq{} lets one declare
constants that should not be automatically simplifies away, unless the
occur in a context that demands it.

\begin{coq}{name=infix,print}{}
Arguments eq_op {_} _ _ : simpl never.
Eval simpl in forall x y : bool, x == y.
Eval simpl in forall x y : bool, true == false || x == y.
\end{coq}

The first call to \C{simpl} does not reduce away \C{eq\_op}
leaving the expression untouched.  In the second example, it
does reduce to \C{false} the test \C{(true == false)} in order to
simplify the \C{||} connective.

The converse technological issue may arise when canonical structure
inference ``promotes'' the operator name to a projection of the
corresponding canonical monoid structure.

\begin{coq}{name=infix,print}{width=5.3cm}
Implicit Type l : seq nat.
Lemma example F l1 l2 :
 \sum_(i <- l1 ++ l2) F i =
 \sum_(i <- l2 ++ l1) F i.
Proof.
rewrite big_cat.
rewrite /=.
by rewrite addnC -big_cat.
Qed.
\end{coq}
\begin{coqout}{run=roar}{title=Response after line 3,width=6.9cm}
F : nat -> nat
l1, l2 : seq nat
============================
addn_monoid
 (\big[addn_monoid/0]_(i <- l1) F i)
 (\big[addn_monoid/0]_(i <- l2) F i) =
\sum_(i <- (l2 ++ l1)) F i
\end{coqout}

It is not uncommon to see \C{/=} switch in purely algebraic proofs
(where no computation is really involved) just to clean up the display
of the current conjecture.


% TODO : Discuss also the dangers of breaking abstraction barriers, as a
% good practice.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Implement \lstinline/[foo of nat]/}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{Phantom}
\mcbLEVEL{3}
\mcbsection{Querying the canonical structures data base}\label{sec:phantom}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

It is possible to  ask \Coq{} if a certain term does validate an
interface.  For example, to check if \C{addn} forms a monoid one can
\C{Check [law of addn]}.  A notation of this kind exists for any
interface, for example \C{[eqType of nat]} is another valid query to
check if \C{nat} is equipped with a canonical comparison function.

This mechanism can also be used to craft notations that assert
if one of their arguments validates an interface.  For example
imagine one wants to define the concept of finite set as an
alias of \C{seq T} but such that only values for \C{T} being
\C{eqType}s are accepted.

This rest of this section introduces the general mechanism of phantom
types used to trigger canonical structure resolution.

First of all, canonical structure resolution kicks in during
unification that in turn is used to compare types.  Types are
compared whenever a function is applied to an argument, and in
particular the type expected by the function and the one of the
argument are unified.  What we need to craft is is a mechanism that
takes any input term (proper terms like \C{addn} but also types as \C{nat})
an puts it into a type.  We will then wire things up so that such
type is unified with another one containing the application of 
a projection to an unknown canonical structure instance.

\begin{coq}{name=phantom}{}
Inductive phantom (T : Type) (p : Type) := Phantom.
\end{coq}

The \C{Phantom} constructor expects two arguments.  If we apply
it to \C{nat} as in \C{(Phantom Type nat)} we obtain a term
of type \C{(phantom Type nat)}.  If we apply it to \C{addn} as
in \C{(Phantom (nat -> nat -> nat) addn)} we obtain a term
pf type \C{(phantom (nat -> nat -> nat) addn)}.  In both cases the
input term (\C{nat} and \C{addn} respectively) is now part of a type.

The following example defined a notation \C{{set T}} that
fails if \C{T} is not an \C{eqType} but is an alias of the type
\C{(seq T)} that imposes no requirement on the type argument. 

\begin{coq}{name=set}{}
Definition set_of : (T : eqType) (_ : phantom Type (Equality.sort T)) := seq T.
Notation "{ 'set' T }" := (set_of _ (Phantom _ T))
  (at level 0, format "{ 'set'  T }") : type_scope.
\end{coq}

When type inference runs on \C{\{set nat\}} the underlying term being
typed is \C{(set\_of ?T (Phantom ?N nat))}.
The unification problem arising for the last argument of \C{set\_of}
is \C{(phantom Type (Equality.sort ?T))} versus 
\C{(phantom Type nat)}, that in turn contains the sub problem
we are interested in: \C{(Equality.sort ?T)} versus \C{nat}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercises}

%%%%%%%%%%
\begin{Exercise}{label=ex:sumoddsquare,difficulty=0,title={Sum of $2n$ odd numbers}}
Show the following lemma using the theory of big operators
\begin{coq}{name=bigop222}{}
Lemma sum_odd n : \sum_(0 <= i < n.*2 | odd i) i = n^2.
\end{coq}
\end{Exercise}

\subsection{Solutions}

%%%%%%%%%
\begin{Answer}[ref=ex:leq]
\begin{coq}{name=bigop222}{}
Lemma sum_odd n : \sum_(0 <= i < n.*2 | odd i) i = n^2.
Proof.
elim: n => [|n IHn]; first by rewrite unlock.
rewrite doubleS big_mkcond 2?big_nat_recr // -big_mkcond /=.
by rewrite {}IHn odd_double /= addn0 -addnn -!mulnn; ring.
Qed.
\end{coq}
\end{Answer}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \mcbLEARN{difference with type classes, limitations}
% \mcbREQUIRE{RecCanonical,Coqercions}
% \mcbPROVIDE{}
% \mcbLEVEL{2}
% \mcbsection{Discussion about type inference}\label{sec:typeinfrelated}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% NOT sure I want to keep that discussion.
%
% The points I want to make are:
% \begin{itemize}
% \item during type inference, HO infers (morally) the minimum
% 	info necessary to make things well typed (if we were 1st order
% 	that would really be true).
% 	hence we KNOW when CS inference is triggered EXACTLY.
% 	this is a big difference w.r.t. type classes. It is like a
% 	Prolog program where goals are reordered randomly
% \item I also want to talk about the overlapping instances problem,
% 	that is ``easy'' with TC, hard with CS and envisage an
% 	extension.
% \item limitation of coercions, from both the usability perspective and
% 	the expressive power they offer
% \end{itemize}
