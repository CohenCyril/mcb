\Chapter{Boolean reflection}{ Advanced specifications}\label{ch:boolrefl}

% in addition to the photos:
% \begin{itemize}
% \item talk about /= in 2 as a decorator for elim on a list (since arithmetics is all loked with nosimpl).
% \item talk about nosimpl in 3.3, say that according to our experience simpl is not
% always a good idea hence nosimpl.
% \item good practice (3.3 or 3.4): state and prove the fixpoint unfolding/folding equations.
% \end{itemize}



%\section{Motivations}

At this stage, we are in presence of one of the main issues in the
representation of mathematics in a formal language: very often,
several datastructures can be used to represent a same mathematical
definition or statement. But this choice may have a significant impact
on the upcoming layers of formalized theories. We have seen so far two
ways of expressing logical statements: using boolean predicates and
truth values on one hand, and using logical connectives and the
\C{Prop} sort on the other. For instance, in order to define the
predicate ``the sequence \C{s} has at least one element satisfying the
(boolean) predicate \C{a}'', we can either use a boolean predicate:

\begin{coq}{}{}
Fixpoint |*has*| {T : Type} (a : T -> bool) (s : seq T) : bool :=
  if s is x :: s' then a x || has s' else false.
\end{coq}

or we can use an alternate formula, like for instance:\marginnote{Is
  exists2 presented in the previous section?}

\begin{coq}{}{}
Definition |*has_prop*|  {T : Type} (a : T -> bool) (x0 : T) (s : seq T) :=
   exists2 i, i < size s & a (nth x0 s i)
\end{coq}

Term \C{(has a s)} is a boolean value, hence a hypothesis
\C{s_has_a : has a s} can easily be used in a proof to perform a case
analysis on the fact that sequence
\C{s} has an element such that \C{a} holds, using the \C{case} tactic:

\begin{coq}{}{}
case: s_has_a.
\end{coq}
As we already noted, computation provides some automation for free, as
for instance in order to establish that \C{(has odd [:: 3; 2; 7]) =
  true}, we only need to observe that the left hand-side \emph{computes} to
\C{true}.

It is not as immediate to perform a similar case analysis in a proof
using the alternate version \C{s_has_aP : has_prop a x0 s}. On the
other hand, this phrasing of the hypothesis easily gives access to the
value of the index at which the witness is to be found:

\begin{coq}{}{}
case: s_has_aP => [n asn].
\end{coq}
introduces in the context of the goal a natural number \C{n : nat} and
the fact \C{asn : a (nth x0 s n)}. In order to establish that
\C{(has_prop a x0 s)} we cannot resort to computation, but we can
on the other hand prove it by providing the index at which a witness is
to be found  --plus a proof of this fact-- which may be better suited
for instance to an abstract sequence \C{s}.

In summary, boolean statements are especially convenient for excluded
middle arguments and its variants (contrapositive, reductio ad
absurdum,...). They furthermore provide a form of small step
automation by computation\footnote{They moreover allow for
  proof-irrelevant specifications. This feature is largely used
  throughout the Mathematical Components library but beyond the scope
  of the present chapter: it will be the topic of
  Chapter~\ref{ch:sigmabool}.}. Specification in the \C{Prop} sort
are structured logical statements, that can be ``destructed'' to
provide witnesses (of existential statements), instances (of universal
statements), subformulae (of conjunctions),... They are proved by
deduction, building proof trees made with the rules of the
logic. Formalizing a predicate by the means of a boolean specification
requires implementing a form of decision
procedure and possibly proving a specification lemma if
the code of the procedure is not a self-explanatory description of the
standard axiomatic description of the mathematical notion. For instance a
boolean definition \C{|*prime*| : nat -> bool} implements a complete
primality test, which requires a companion lemma proving that it is
equivalent to the usual definition in terms of proper
divisors. Postulating the existence of such a decision procedure for a
given specification is akin to assuming that the excluded middle
principle holds on the corresponding predicate.

The boolean reflection methodology proposes to avoid
committing to one or the other of these options, providing enough
infrastructure to ease the bureaucracy of navigating between the two.
The \C{is_true} correction, which we have been using since the early
pages of Chapter~\ref{ch:proofs} is in fact one ingredient of this
infrastructure.\marginnote{We should now decide what is said in the
  previous chapter and what we say here about this coercion.} Indeed
this coercion turns a boolean value into a \C{Prop} statement, that
can be used as the statement of a theorem or of a hypothesis. It
hides however an equality than can also be used with the \C{rewrite}
tactic, for instance to perform local modification in goals that can
incidentally trigger larger simplifications when they combine well with
computations. \marginnote{Give an example here. Do we need to mention
  setoid rewriting here for Coq users?}


\section{Views}

\subsection{Relating statements in \C{bool} and \C{Prop}}\label{ssec:boolProp}

How to best formalize the equivalence between a boolean value \C{b}
and a statement \C{P : Prop}? The most direct way would be to use the
conjunction of the two converse applications:
\marginnote{We should say earlier what the notation \C{<->} hides.}

\begin{coq}{}{}
Definition |*bool_Prop_equiv*| (P : Prop) (b : bool) := b = true <-> P.
\end{coq}
Yet as we shall see in this section, we can improve the phrasing of
this logical sentence, in order to improve its usability. For
instance, although \C{(bool_Prop_equiv P b)} implies that the excluded
middle holds for \C{P}, it does not provide directly a convenient way
to reason by case analysis on the fact that \C{P} holds or not, or to
use its companion version \C{b = false <-> ~ P}. The following proof
script illustrates the kind of undesirable bureaucracy entailed by
this wording:

\begin{coq}{}{}
Lemma |*test_bool_Prop_equiv*| b P : bool_Prop_equiv P b -> P \/ ~ P.
Proof.
rewrite /bool_Prop_equiv; case: b; case => hlr hrl.
  left; exact: hlr.
by right => hP; move: (hrl hP).
Qed.
\end{coq}

We could try
alternate formulations based on the connectives seen in
section~\ref{sec:ttch}, like for instance
\C{(b = true /\\ P) \\/ (b = false /\\ ~ P)}, but a better solution is
to use an ad-hoc inductive definition, that ressembles this
disjunction of conjunctions: we inline the two constructors of a
disjunction and each of these constructors has the two arguments of
the conjunction's single constructor:

\begin{coq}{}{label=lst:reflect1}
Inductive |*reflect*| (P : Prop) (b : bool) : Prop :=
|ReflectT (p : P)    (e : b = true)
|ReflectF (np : ~ P) (e : b = false)
\end{coq}

We can prove that the statement \C{reflect P b} is actually equivalent
to the double implication. Exercise, prove:

\begin{coq}{}{width=13cm}
Lemma |*iffP_lr*| (P : Prop) (b : bool) : (P -> b) -> (b -> P) -> reflect P b.

Lemma |*iffP_rl*| (P : Prop) (b : bool) : reflect P b -> ((P -> b) /\ (b -> P)).
\end{coq}

Let us illustrate the benefits of this alternate specialized double
implication:

\begin{coq}{}{width=5cm}
Lemma |*test_reflect*| b P :
  reflect P b -> P \/ ~ P.
Proof.
case.
\end{coq}
\begin{coqout}{}{width=6cm}
  b : bool
  P : Prop
  ============================
   P -> b = true -> P \/ ~ P

subgoal 2 (ID 100) is:
 ~ P -> b = false -> P \/ ~ P
\end{coqout}

A simple case analysis on the hypothesis \C{(reflect P b)} exposes in
each branch both versions of the statement: one in its \C{Prop}
version, and the corresponding boolean equation. Note that the actual
\C{reflect} predicate defined in the \C{ssrbool} library is actually
slightly different from the one we give in Listing~\ref{lst:reflect1}:
this version misses an ultimate refinement\footnote{Moreover the \C{reflect}
predicate is in fact in sort \C{Type}, which will hopefully make sense
when reading Chapter~\ref{ch:sigmabool}}, that will be presented in
Section~\ref{ssec:specs}. Until we reach Section~\ref{ssec:specs}, we
will act as if Listing~\ref{lst:reflect1} was the official definition
of \C{reflect}.

\marginnote{Do not really know how to make this clearer... Plus the
  LaTeX counter for listings could be improved.}

We start our collection of links between boolean and \C{Prop}
statements with the lemmas relating boolean connectives with their
\C{Prop} version:

\begin{coq}{}{}
Lemma |*andP*| : reflect (b1 /\ b2) (b1 && b2).
Proof. by case b1; case b2; constructor=> //; case. Qed.

Lemma |*orP*| : reflect (b1 \/ b2) (b1 || b2).
Proof. by case b1; case b2; constructor; auto; case. Qed.

Lemma |*implyP*| : reflect (b1 -> b2) (b1 ==> b2).
Proof. by case b1; case b2; constructor; auto. Qed.
\end{coq}

Observe that the proof of each of these lemmas is a simple inspection by
case analysis of the truth table of the boolean formula. More
generally, a theorem stating an equivalence between a boolean
expression and a \C{Prop} statement is called a \emph{view}. Next
section is devoted to the proof and usage of more involved views.

\subsection{Proving and using views}

Views are also used to specify types equipped with a
\emph{decidable equality}, by showing that the equality predicate
\C{eq} (seen in Section~\ref{ssec:indtypes}) is implemented by a
certain boolean equality test. For instance, we can specify the
boolean equality test on type \C{nat} implemented in
Chapter~\ref{ch:prog} as:

\begin{coq}{}{}
Lemma |*eqnP*| (n m : nat) : reflect (n = m) (eqn n m).
\end{coq}

\marginnote{In fact, \C{eqnP} is stated using Equality.axiom}
Each implication can be proved by a simple induction on one of the
natural numbers, but we still need to generate the two subgoals
corresponding to these implications, as the \C{split} tactic is of no
help here.

\marginnote{Proving these implications would be a good exercise in the
  previous chapter. Solution descibed below in (comments in) the sources.}

% Indeed if \C{n = m} holds, then we can prove that
% \C{eqn n m = true} by first substituting \C{m} by \C{n} and then
% proving that \C{eqn n n = true} by induction on \C{n}. Now if
% \C{eqn n m = true}, we will show that \C{n = m} holds by
% reasoning by induction on \C{n} and by case analysis on \C{m}. The
% base case is easy: if \C{n} is \C{O} and \C{m} is not, the \C{eqn n m}
% evaluates to \C{false} and the hypothesis \C{eqn n m = true} is thus
% convertible to \C{false = true}, which allows reductio ad absurdum. In
% the recursive case, we know that \C{forall m, eqn n m = true -> n = m}
% and we want to prove that
% \C{forall m, eqn n.+1 m = true -> n.+1 = m}. Again, we perform a case
% analysis on \C{m} and the case when \C{m} is zero is easy. Now if
% \C{m} is of the form \C{k.+1}, we need to prove that
% \C{eqn n.+1 k.+1 =true -> n.+1 = k.+1}, or equivalently (by
% conversion) that
% \C{eqn n k =true -> n.+1 = k.+1}. The premise of this implication can
% feed our induction hypothesis and we thus know that \C{n = k}, which
% is sufficient to prove that \C{n.+1 = k.+1} by substitution.

In order to trigger this braching in the proof tree, we resort to the
bridge between the \C{reflect} predicate and a double implication.
The \C{ssrbool} library actually provides a more general version of
this bridge than the one we proved in exercise in
Section~\ref{ssec:boolProp}:

\begin{coq}{}{}
About iffP.
\end{coq}

\begin{coqout}{}{}
|*iffP*| :
forall (P Q : Prop) (b : bool),
reflect P b -> (P -> Q) -> (Q -> P) -> reflect Q b

Arguments P, Q, b are implicit
\end{coqout}
Lemma \C{|*iffP*|} indeed relates two equivalences \C{(reflect P b)}
and \C{(reflect Q b)} involving a same boolean \C{b} but different
\C{Prop} statements \C{P} and \C{Q}, as soon as one
provides a proof of the usual double implication between \C{P} and
\C{Q}. \marginnote{Prove it as an exercise?}

Statement \C{(@iffP_lr P b)} in the exercise can be obtained as the
specialization \C{(@iffP _ _ (@idP b))} where \C{|*idP*|} is the
trivial reflexive\footnote{Note that the first occurrence of \C{b} is
coerced to \C{Prop} by \C{is\_true}} equivalence:

\begin{coq}{}{}
Lemma |*idP*| {b : bool} : reflect b b.
\end{coq}

We can now come back to the proof of lemma \C{eqnP}, and start its
proof script with:
\marginnote{The tuning of implicits is crucial for the
\C{apply: (iffP idP)} to behave correctly.}

\begin{coq}{}{width=7cm}
Lemma |*eqnP*| {n m : nat} :
  reflect (n = m) (eqn n m).
Proof.
apply: (iffP idP).
\end{coq}
\begin{coqout}{}{width=5cm}
n : nat
m : nat
===================
 m = n -> eqn m n

subgoal 2 (ID 365) is:
 eqn m n -> m = n
\end{coqout}
Exercise: finish the proof.

In fact the library does not feature the specialization \C{iffP_lr},
and the idiom to remember in order to prove a reflection lemma by
double implication is the \C{apply: (iffP idP)} command. Let us now
showcase the usage of the more genral for of \C{iffP} by proving
that a type equipped with an injection in type \C{nat} can be equipped
with a decidable equality:

\begin{coq}{}{}
Lemma |*nat_inj_eqAxiom*| (T : Type) (f : T -> nat) :
  injective f -> reflect (x = y) (eqn (f x) (f y)).
\end{coq}
The equality decision procedure indeed just consists in pre-applying
the injection \C{f} to the decision procedure \C{eqn} available on
type \C{nat}. Since we already know that \C{eqn} is a decision
procedure for equality, we just need to prove that \C{x = y} if and
only if \C{f x = f y}, which  follows directly from the injectivity of
\C{f}. Using \C{iffP}, a single proof command splits the goal into two
implications, replacing on the fly the evaluation
\C{(eqn (f x) (f y))} by the \C{Prop} equality \C{f x = f y}:

\begin{coq}{}{width=7.7cm}
Lemma |*nat_inj_eq*| (T : Type) (f : T -> nat) :
injective f ->
  reflect (x = y) (eqn (f x) (f y)).
Proof.
move=> f_inj.
apply: (iffP eqnP).
\end{coq}
\begin{coqout}{}{width=4.3cm}
x : T
y : T
f_inj : injective f
====================
x = y -> f x = f y

subgoal 2 (ID 403) is:
 f x = f y -> x = y
\end{coqout}
Exercise: finish the proof.

The latter example illustrates the convenience of combining an action
on a goal, here breaking an equivalence into one subgoal per
implication, with a change of viewpoint, here by the means of the
\C{eqnP} view. This combination of atomic proof steps is pervasive in
a library designed using the boolean reflection methodology: the
ssreflect tactic language therefore provides so-called view features,
designed to facilitate more generally the combination of a tactic or
intro-pattern with the application of a view.

For instance, suppose that one wants to access the components of a
conjunctive hypothesis, stated as a boolean conjunction like in:

\begin{coq}{}{}
Lemma example n m k : k <= n -> (n <= m) && (m <= k) -> n = k.
\end{coq}

Then we can use lemma \C{andP} in a \emph{view intro-pattern}:

\begin{coq}{}{width=7cm}
Lemma example n m k :
  k <= n ->
    (n <= m) && (m <= k) -> n = k.
Proof.
move=> lekn /andP.
\end{coq}
\begin{coqout}{}{width=5cm}
n : nat
m : bool
k : nat
lekn : k <= n
==========================
 n <= m /\ m <= k ->
   n = k
\end{coqout}

The view intro-pattern \C{/andP} has \emph{applied} view \C{andP} to
the head hypothesis \C{(n <= m) && (m <= k)} and tranformed it into
its equivalent form \C{(n <= m) /\\ (m <= k)}. Note that strictly
speaking, view \C{andP} does not have the shape of an implication,
that can be fed with a proof of its premise: it is (isomorphic to) the
conjunction of \emph{two} such implications. The \emph{view mechanism}
implemented in the tactic language has automatically guessed and
inserted a term which plays the role of an adaptator, which acts as if
the right direction of the double implication has been guessed, as
well as the possible missing arguments of the view.

More precisely in this case, the \C{/andP} intro pattern has changed
hypothesis \C{top : (n <= m) && (m <= k) (* = true *)} into
\C{elimTF andP top : (n <= m) /\\ (m <= k)},
where \C{elimTF} is the ``adaptator'' which has been
inserted\footnote{Adaptators are in fact called \C{Hint Views},
  registered by the eponym vernacular command. See~\cite{ssrman} for
  more details}:

\begin{coq}{}{}
Lemma |*elimTF*| {P Q : Prop} {b c : bool} :
  reflect P b -> b = c -> if c then P else ~ P.
\end{coq}
Term \C{elimTF andP top} hence has type
\C{if true then (n <= m) /\ (m <= k) else ~ ((n <= m) /\\ (m <= k))},
which reduces to \C{((n <= m) /\\ (m <= k))}.

\marginnote{Show other examples of inserted hint views? Like negation...}

Going back to  our example: we can then chain this view with a casing
intro-pattern to break the conjunction and introduce its components:

\begin{coq}{}{width=7cm}
Lemma example n m k :
  k <= n -> (n <= m) && (m <= k) -> n = k.
Proof.
move=> lekn /andP [lenm lemk].
\end{coq}
\begin{coqout}{}{width=5.1cm}
n : nat
m : bool
k : nat
lekn : k <= n
lenm : n <= m
lemk : m <= k
===========================
n = k
\end{coqout}

As \C{(n <= m)} is a notation for \C{n - m == 0}, we can use view
\C{eqnP} in order to transform this hypothesis on the fly. Observe the
new shape of the \C{leqnm} hypothesis:

\begin{coq}{}{width=7cm}
Lemma example n m k :
  k <= n -> (n <= m) && (m <= k) -> n = k.
Proof.
move=> lekn /andP [/eqnP lenm lemk].
\end{coq}
\begin{coqout}{}{width=5.1cm}
n : nat
m : bool
k : nat
lekn : k <= n
lenm : n - m = 0
lemk : m <= k
===========================
n = k
\end{coqout}

Combining wisely the facilities of \C{Prop} structural reasoning with
the ease to reason by equivalence via rewriting of boolean identities
leads to concise proofs and proof scripts and prevent from too low
level proof steps. 

Let us now move to a non artificial example and dissect the proof that
\C{(_ <= _)} is a total relation, expressed as a boolean statement:

\begin{coq}{}{}
Lemma |*leq_total*| m n : (m <= n) || (m >= n).
\end{coq}

The first step of the proof is to view this disjunction as an
implication, using the classical equivalence and a negated premise:

\begin{coq}{}{width=7.6cm}
Lemma |*leq_total*| m n : (m <= n) || (m >= n).
Proof.
rewrite -implyNb.
\end{coq}
\begin{coqout}{}{width=4.7cm}
m : nat
n : nat
=====================
~~ (m <= n) ==> (n <= m)
\end{coqout}

This premise can be seen as \C{n < m}:

\begin{coq}{}{width=7.6cm}
Lemma |*leq_total*| m n : (m <= n) || (m >= n).
Proof.
rewrite -implyNb -ltnNge.
\end{coq}
\begin{coqout}{}{width=4.5cm}
m : nat
n : nat
=====================
(n < m) ==> (n <= m)
\end{coqout}

This is now an instance of the weakening property of the comparison,
except that it is expressed with a boolean implication. But the view
mechanism not only exists in intro-patterns: it can also be used in
combination with the \C{apply} tactic, to apply a view to a given goal
with a minimal amount of bureaucracy:

\begin{coq}{}{width=7.6cm}
Lemma |*leq_total*| m n : (m <= n) || (m >= n).
Proof.
rewrite -implyNb -ltnNge; apply/implyP.
\end{coq}
\begin{coqout}{}{width=4.5cm}
m : nat
n : nat
=====================
(n < m) -> (n <= m)
\end{coqout}

We can now conclude the proof:

\begin{coq}{}{}
Lemma |*leq_total*| m n : (m <= n) || (m >= n).
Proof. by rewrite -implyNb -ltnNge; apply/implyP; apply: ltnW. Qed.
\end{coq}

The \C{case} tactic also combines with the \C{view} mechansism, which
eases reasoning by cases along a disjunction expressed with a boolean
statement, like \C{leq_total}. Example:

\begin{coq}{}{}
Lemma |*leq_max m n1 n2*| :
  (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
case/orP: (leq_total n2 n1) => le_n12.
\end{coq}

That results in:

\begin{coqout}{}{}
m : nat
n1 : nat
n2 : nat
le_n12 : n2 <= n1
============================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal 2 (ID 478) is:
 (m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

Finally, the \C{rewrite} tactic can also be used to work with views:

\begin{coq}{}{}
Lemma |*maxn_idPl*| {m n} : reflect (maxn m n = m) (m >= n).
Proof. (* exercise *) Qed.

Lemma |*leq_max m n1 n2*| :
  (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
case/orP: (leq_total n2 n1) => le_n12. rewrite (maxn_idPl le_n12).
\end{coq}

Leading to:

\begin{coqout}{}{}

  m : nat
  n1 : nat
  n2 : nat
  le_n12 : n2 <= n1
  ============================
   (m <= n1) = (m <= n1) || (m <= n2)

subgoal 2 (ID 478) is:
 (m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

\marginnote{We could propose another exercise in next section in order
to factor this proof with a \C{wlog}.}
\begin{itemize}

% \item Example of \C{eqnP}, that is \C{eqP} specialized to
%   \C{nat}. Proof using \C{(iffP idP)}. Explain \C{iffP} and \C{idP} is
%   the dummay case.

% \item Another example: Simplified instance of \C{inj_eqAxiom} in
%   section  \C{TransferEqType} of \C{eqtype.v}, with \C{nat} as
%   codomain. Proof with \C{(iffP eqnP)}.

% \item Using views, with tactics. First, example of using \C{eqnP} in
%   an intro pattern, like \C{=> /eqnP ->}. Note that the direction in
%   which the view should be used has been guessed
%   automatically. Explain which adapter has been inserted (as a hint).

% \item Then show the cute proof of \C{leq_total}, which features
%   \C{apply/implyP}.

\item Finally, show \C{case/orP: (leq_total n m)}. May be a first
  simple and dummy example. Then one possibility is
  to show a simplified version of the proof of \C{leq_max}, removing
  the \C{without loss}. This features \C{case/orP: (leq_total n2 n1)}
  and \C{rewrite (maxn_idPl le_n21)} which uses the \C{elimT} coercion.
  This could be reused in the next section, to illustrate \C{wlog}.


\item There are more adaptors than \C{introT, introF, elimT, elimF},
  in particular with negations \C{elimN,...} and \C{apply/v1/v2}.

\end{itemize}

Note that the view feature in the tactic language is there to combine an
action (tactic or intro pattern) with a change of world. Order in
which we could introduce it: \C{/eqP ->}, \C{/andP [h1 h2]},
\C{/orP [h1 | h2]}. May be mention \C{=> /v1 /v2} as a side remark.

% It is the fragment of decidable stuff (EM as case).
% It is a concrete data type on which you can program (SSR), automation by
% computation.

% % \begin{coq}{name=Ex}{}
% % Lemma muln_eq0 m n :
% %   ((m * n = 0) -> (m = 0) \/ (n = 0)) /\
% %   ((m = 0) \/ (n = 0) -> (m * n = 0))
% % Proof.
% % Qed.
% %
% % Lemma leq_mul2l m n1 n2 :
% %   (m * n1 <= m * n2) = (m == 0) || (n1 <= n2).
% % Proof.
% % Qed.
% % \end{coq}



% \begin{coq}{name=Ex}{}
% Lemma leq0n n : (0 <= n) (* = true *).
% \end{coq}

% NOt everything can be in bool, e.g. exists or a real reasoning by cases
% on a disjunction. Inductives give you the tree structure in natural
% deduction, not bools.

% \begin{coq}{name=Ex}{}
% Lemma ...
% case/orbP : (leq_total n m)
% \end{coq}

% We need lemmas to relate

% \begin{coq}{name=Meaning of reflect}{}
% Definition reflect P b : Prop :=  b -> P /\ P -> b

% Lemma orbP p q : reflect (p \/ q) (p || q).
% \end{coq}

% so frequent and so many variations that we have proper infrastructure like
% being able to invoke views everywhere and have 1 view per connective (negate or
% not...).

% \begin{coq}{}{}
% Lemma introT  : P -> b.            Proof using Pb. exact: introTF true _. Qed.
% Lemma introF  : ~ P -> b = false.  Proof using Pb. exact: introTF false _. Qed.
% Lemma introN  : ~ P -> ~~ b.       Proof using Pb. exact: introNTF true _. Qed.
% Lemma introNf : P -> ~~ b = false. Proof using Pb. exact: introNTF false _. Qed.
% Lemma introTn : ~ P -> b'.         Proof using Pb'. exact: introTFn true _. Qed.
% Lemma introFn : P -> b' = false.   Proof using Pb'. exact: introTFn false _. Qed.
% \end{coq}

% \section{how to use reflect lemmas as tactic decorators}

% we make examples with andP orP negP in move/P, apply/P, case/P.

% we explain the hint view, plus the extra impl arguments.

% some view can be partial, A -> B -> reflect B c.

% \subsection{The view mechanism in intro pattern}

%   a == b \&\& bb

% views applied to top, inline destructuring and subst:
%   => /andP[/eqP-> pb] ->.

% Fwd and backward declarative steps.
% have : P x := ... H ...
% suff.

% Handling symmetries:
% gen have: x Hx / P x.

% managing large goals and contexts: set, -/x /x

% help the reader with typographical comments, like leaving an empty
% line in latex (here we use bullets).

Not everything needs to be a tactic, the logic is powerful
enough to express special connectives that induce a line of
reasoning. Hence the next section.

\section{Advanced, practical, statements}

general talk about the fact that statements/definition do matter: not only for
their meaning but also because they have implications on the
usability/practicality in the rest of the library.  At least two classes of
techniques, the ones based on the logic (bool refl, reflect, classically, order
of forall when instantiation done via CH) and the ones based on the support of
the prover (implicit args, type inference CS, Hint Resolve).

More in general, this has to be mentioned in the main intro of the book, here
we revise the idea.

\subsection{Inductive specs with indices}\label{ssec:specs}
What we did for reflect, an ad hoc connective, to model a line of reasoning is
a recurrent pattern in the \mcbMC{} library: the ``spec'' predicates.  Specs
are particularly handy  because inductive predicates, via their elimination
rule, accesses a special feature of the type theory of Coq: implicit equations
/ automatic substitution.

If we look at reflect, and its use, one is very likely to substitute b
for its value in each branch of the case.

\begin{coq}{}{}
Inductive |*reflect*| (P : Prop) (b : bool) : Prop :=
|ReflectT (p : P)    (e : b = true)
|ReflectF (np : ~ P) (e : b = false)
\end{coq}

This alternative formulation makes the equation implicitly stated and
also automatically substituted during case analysis.

\begin{coq}{}{}
Inductive |*reflect*| (P : Prop) : bool -> Prop :=
|ReflectT (p : P)    : reflect P true
|ReflectF (np : ~ P) : reflect P false
\end{coq}

Here the second argument of \C{reflect} is said to be an \emph{index}
and it is allowed to vary depending on the constructor: \C{ReflecT} always
builds a term of type \C{(reflect P true)} while \C{ReflectF} builds
a term of type \C{(reflect P false)}.
Example:

\begin{coq}{}{}
case: (andP a b) => [ab|nab]
\end{coq}

\begin{coqout}{}{width=6cm}
a, b : bool
========================
a && b ==> (a == b)
\end{coqout}
\begin{coqout}{}{width=6cm}
a, b : bool
ab : a /\ b
========================
true || a == b

subgoal 2 is:
false || a == b
\end{coqout}

Every time a term of type \C{(reflect (a /\\ b) (a && b))} is eliminated, the
following happens:
\begin{enumerate}
\item 2 subgoals are generated
\item in the first one (corresponding to \C{ReflectT}) a new hyp is
  available (\C{(a /\\ b)}) and all occurrences of the boolean
  expression \C{(a && b)} are replaced by \C{true} (the value of the index
  for \C{ReflectT}).
\item in the first one (corresponding to \C{ReflectF}) a new hyp is
  available (\C{\~(a /\\ b)}) and all occurrences of the boolean
  expression \C{(a && b)} are replaced by \C{false}, the value of
  the index for \C{ReflectF}.
\end{enumerate}

The second goal becomes trivial, hence we can finish

\begin{coq}{}{}
case: (andP a b) => [[-> ->] | //]
\end{coq}

An even better tactic is

\begin{coq}{}{}
case: (andP _ _) => [[-> ->] | //]
\end{coq}

In this case the boolean expression replaced by true/false is \C{(_ && _)}.
Trailing \C{_} are also added automatically by \C{case} leading to the
idiomatic

\begin{coq}{}{}
case: andP => [[-> ->] | //]
\end{coq}

Note the similarity between matching \C{(_ && _)} and the job of rewrite.

On the same line, we present \C{leqP} that still models a case split but
this time specialized to the order relation (and its negation) substituting
both with true/false.  Just mention \C{ltngtP}, that is the proof that
a boolean predicate (because of its 2 valued nature) can model a concept
with 3 cases as well via this spec mechanism.  Or that the same concept,
depending on the proof you need to do, may benefit from different natures
of case splits.

\mantra{the structure of the proof shall not be driven by the syntax (head
symbol) of the definition/predicate under study but by the view/spec you apply
to it}

Just show a use of \C{ifP} and/or \C{ifPn} and the fact that its pattern is
quite smart/small wrt the expression it typically handles (3 chars in place of\\
\C{(if cond then branch else alternative)}).

Also show the adaptor altP, that is particularly useful with eqnP and boolP.

% \subsection{TBD: dependent elimination (**)}

% explain return match clause.  Maybe just the syntax we provide here and
% there, the / annotation for elim/case, and then point to other texts explaining
% the thing.  \mcbMC{} does not use such thing but for spec.

% \subsection{Other tools to craft good statements}

% \begin{itemize}
% \item Use macros (\C{left_commutative} or notations like
% \C{\{in A, bijective f\}}, and3, ...)
% \item Use naming conventions
% \item Classically (do not insist too much)
% \item iff (\C{AGM}): find examples?
% \item Tuning of implicit arguments
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Towards real proofs}

Real proofs also deal with structure (readability, naming, context handling and
robustness), repetitions (like symmetry).  This section works out a few
examples illustrating good practices and specific proof
commands. Start with infinity of primes (and the two lemmas it relies
on), in order to introduce \C{have} and to see how one can work on a
goal, even in implicative shape. Then this one:

Example:
$$
\forall n_1, n_2, m, \quad m \le max(n_1,n_2)
\Leftrightarrow m \le n_1 \textrm{ or } m \le n_2
$$

The proof goes like that: without loss of generality we can assume that
$n_2$ is greater or equal to $n_1$, hence $n_2$ is the maximum between
$n_1$ and $n_2$.  Under this assumption it is sufficient to check
that $m \le n_2$ holds iff either $m \le n_2$ or $m \le n_1$.
The only non trivial case is when we suppose $m \le n_1$ and
we need to prove $m \le n_2$ which holds by transitivity.\hfill$\square$

As usual we model double implication as an equality between two
boolean expressions:

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
\end{coq}

The proof uses the following (new) lemmas.  Pay attention to
\C{orb_idr}.

\begin{coq}{}{title=tools}
Lemma orb_idr (a b : bool) : (b -> a) -> a || b = a.
Lemma maxn_idPl {m n} : reflect (maxn m n = m) (m >= n).
Lemma leq_total m n : (m <= n) || (m >= n).
\end{coq}

Our first take takes no advantage of the symmetry argument and
begins by reasoning by cases on the order relation,
we name the resulting hyp with a meaningful name and close to
the proof step that generates it (to ease tracking who adds what).

\begin{coq}{}{}
Proof.
case/orP: (leq_total n2 n1) => [le_n21|le_n12].
  rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
  by apply: leq_trans le_mn2 le_n21.
rewrite maxnC orbC.
rewrite (maxn_idPl le_n12) orb_idr // => le_mn1.
by apply: leq_trans le_mn1 le_n12.
Qed.
\end{coq}

alternative with a more declarative have (probably useless).

\begin{coq}{}{}
Proof.
have /orP[le_n21|le_n12] := leq_total n2 n1.
  rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
  by apply: leq_trans le_mn2 le_n21.
rewrite maxnC orbC.
rewrite (maxn_idPl le_n12) orb_idr // => le_mn1.
by apply: leq_trans le_mn1 le_n12.
Qed.
\end{coq}


2 goals, hence indentation.

\begin{coqout}{}{title=Output line 3,width=8cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
========================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal 2 is:
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

The first goal is simplified by
reqriting with the \C{maxn_idPl} view (recall elimT).  Then
\C{orb_idr} trivializes the main goal and generates a side condition
with an extra hyp we name \C{le_mn2}

\begin{coqout}{}{title=Output line 4a,width=6.7cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
========================
(m <= n1) = (m <= n1) || (m <= n2)

subgoal 2 is: ...
\end{coqout}
\begin{coqout}{}{title=Output line 4b,width=5.3cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
le_mn2 : m <= n2
========================
m <= n1

subgoal 2 is: ...
\end{coqout}

Line 3 combines by transitivity the two hyps to conclude.
Since it closes the proof branch we use the prefix \C{by}
to asserts the goal is solved and visually signal the end of the paragraph.
(maybe use \C{exact}).

Line 4 commutes the max and or, hence we can copy paste the first paragraph
also to close the second goal.

Next take factorizes a generalization of goal to take care of symmetry.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
have th_sym x y: y <= x -> (m <= maxn x y) = (m <= x) || (m <= y).
  move=> le_n21; rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
  by apply: leq_trans le_mn2 le_n21.
by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
Qed.
\end{coq}

Last line instantiates \C{th_sym} \emph{in each branch} using the corresponding
hypothesis on \C{n1} and \C{n2} generated by the case analysis.

\begin{coqout}{}{}
2 subgoals
m, n1, n2 : nat
th_sym : forall x y : nat,
         y <= x -> (m <= maxn x y) = (m <= x) || (m <= y)
========================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2) ->
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal 2 is:
(m <= maxn n2 n1) = (m <= n2) || (m <= n1) ->
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

This is exactly what is needed in the first branch of the case analysis.
The last subgoal just requires commuting \C{max} and \C{||}.

We prefer to get rid of the easiest part of the proof first, thus
keeping the main branch of the proof non indented. In this case
it amounts to begin by showing why \C{th_sym} suffices to prove the main
goal.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
suff th_sym x y: y <= x -> (m <= maxn x y) = (m <= x) || (m <= y).
  by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
move=> le_n21; rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
by apply: leq_trans le_mn2 le_n21.
Qed.
\end{coq}

Final step, wlog lets us not repeat the goal and abstract it, but
just mention the extra assumption we can take without loosing
generality.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof
wlog le_n21: n1 n2 / n2 <= n1 => [th_sym|].
  by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
by apply: leq_trans le_mn2 le_n21.

by rewrite /maxn le_n21 orb_idr // => le_mn2; apply: leq_trans le_mn2 le_n21.

(* then, recalling apply adds _ we can avoid naming/mentioning le_mn2*)
by rewrite (maxn_idPl le_n21) orb_idr // => ?; apply: leq_trans le_n21.

(* or even better using lemmas in intro pattern + auto generalization
   plus rewriting an is_true... or maybe not *)
by rewrite (maxn_idPl le_n21) orb_idr // => /leq_trans->.
Qed.
\end{coq}

For wlog, say that the block naming \C{th_sym} is optional and frequently
omitted (at the cost of less explicit script).

\begin{coq}{}{}
Lemma edivnP m d :
 let ed := edivn m d in
   ((d > 0) ==> (ed.2 < d)) && (m == ed.1 * d + ed.2).
Proof.
move E: (edivn m d) => ed /=.
case: d => [|d /=] in E *; first by rewrite -E eqxx.
rewrite /edivn /= in E.
rewrite -[m]/(0 * d.+1 + m).
elim: m {-2}m 0 (leqnn m) E => [|n IHn] [??<-|m] //= q le_mn.
rewrite subn_if_gt; case: (leqP d m) => [le_dm|lt_md <- /=]; last first.
  by rewrite ltnS lt_md eqxx.
have le_mdn : m - d <= n by rewrite (leq_trans (leq_subr d m)).
by move/(IHn _ _ le_mdn); rewrite mulSnr -addnA -subSS subnKC.
Qed.
\end{coq}

% May be a real 10 lines proofs would help here. Lemmas about Euclidean
% division?
\begin{itemize}
\item Proofs have a structure, to ensure readability (in a certain
  sense) and maintenance; we list here some tools and good practice.
\item Declare intermediate steps: forward (\C{have}), backward
  (\C{suff}), symmetries (\C{gen have} and mention \C{wlog}),
abbreviations \C{set}
\item: Punctuation to help the reader: bullets, indentation,
  terminating tactics.
\item Good practices: local/early error detection, checkpoints via
  \C{have}, naming policies (lemmas, but also hypotheses and bound
  variables), robust rewrite.
\item keep context clean?
\end{itemize}

% \section{STOP HERE}
% 
% THIS CHAPTER IS ABOUT METHODOLOGY, plus introduces the other logical
% connectives. May be merged into the previous chapter.
% 
% 
% % Where one learns to do proofs.
% % Boolean reflection in practice, views, discussion on the definition of leq,
% % proofs on things defined in the
% % previous chapter, associated tactics, exercises on prime, div,
% % binomial, etc.
% %
% % spec? A new vernacular to declare specs without typing coinductive and
% % by writing explicitly the equations.
% 
% Discussion prop/bool, intuitionism, extraction (we should be able to
% avoid talking about impredicativity, but use Prop for computationally
% irrelevant).
% 
% 
% \begin{itemize}
% \item can we specify all we have written so far using just = and forall? No.
% 	Example dvdn needs exists to be specified
% \item exists, and, or, neg, False, True as inductives (again CH style)
% \item related tactics: split, left, right,exists,case
% \end{itemize}
% 
% Anyway to take advantage of computation (ssr style) we want to
% work with bool as much as possible:
% 
% \begin{itemize}
% \item reflect is the right way to write iff, <->, specialized to bool
% 	so that the proof language recognizes it and offer a bit more ergonomic
% \item is-true
% \item infrastructure for reflect: iffp, altp
% \item no split if goal is \&\& (metodology)
% \end{itemize}
% 
% Writing good statements
% 
% \begin{itemize}
% \item = as iff for bool, because rewrite is easy to use
% \item and3p, spec (drive your proof),
% \item advanced stuff: classically P instead of not-not P (can be
%   skipped for beginners)
% \item in general good quantifications and implicit arguments and good library
% 	makes it possible to work without evars
% \item . \C{<=} . ?= iff .
% \end{itemize}
% 
% Statements do also occur in the middle of proofs.  There we have many ways to
% write them compactly, wlog and have.
% 
% Comparison with other possible ways of writing properties:
% \begin{itemize}
% \item impact of le v.s. leq in a proof
% \end{itemize}
% 
% In this chapter we should distill a description of our
% systematic-reactions, reflexes, to typical situations a
% beginner would screw up. In fact it would be great to explain here the
% mix of Gallina (unless, classically, etc.) and of tactics (wlog,
% have,...) that lead to a convenient modelling of the math prose.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \mcbLEARN{Declaring implicit arguments}
% \mcbREQUIRE{Canonical}
% \mcbPROVIDE{stating lemmas}
% \mcbLEVEL{2}
% \mcbsection{Declaring implicit arguments}\label{sec:declaringimpl}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% here we describe how to choose which arguments are implicit,
% that one has to think ahead how  a lemma is used and hence
% which data type inference has at hand.  Also that the order
% of quantifiers is relevant.
% \begin{itemize}
% \item lemmas: fwd/backward reasoning
% \item equations, look at the concl too, free vars are abstracted
% \item compare with eapply style
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Coercions}
\mcbREQUIRE{}
\mcbPROVIDE{}
\mcbLEVEL{1}
\mcbsection{Notational aspects of specifications}
\label{sec:coercions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Even if the main way to extend the type inference algorithm
% is via Canonical Structures, another mechanism is available
% and used all over the library, even if it plays a minor role.
% The language of Canonical Structures lets one program how the value of
% an implicit argument can be synthesized, but can hardly be used to
% explain \Coq{} how to ``fix'' an ill-typed term written by the user.

When a typing error arises, it always involves three objects:
a term \lstinline/t/, its type \lstinline/ity/ and the type
expected by its context \lstinline/ety/.  Of course, for this
situation to be an error, the two types \lstinline/ity/ and
\lstinline/ety/ do not compare as equal.
The simplest way one has to explain \Coq{} how to fix \lstinline/t/,
is to provide a functional term \lstinline/c/ of type
\lstinline/(ity -> ety)/ that is inserted around \lstinline/t/.
In other words, whenever the user writes \lstinline/t/ in a context
that expects a term of type \lstinline/ety/, the system instead of
raising an errors replaces \lstinline/t/ by \lstinline/(c t)/.

A function automatically inserted by \Coq{} to prevent a type
error is called \emph{coercion}.
The most pervasive coercion in the \mcbMC{} library is
\lstinline/is_true/ that lets one write statements using boolean
predicates.\marginnote{I guess in a way or another is true has
already been introduced}.

\begin{coqdef}{name=istrue}
Lemma example : prime 17.
Proof.
Set Printing Coercions. Redirect "g1" Show.
by [].
Qed.
\end{coqdef}
\begin{coq}{def=istrue}{title=Coercion \lstinline/is_true/,width=6cm}
Lemma example : prime 17.
Proof.  by [].  Qed.
\end{coq}
\coqrun{name=r3}{ssr,istrue}
\begin{coqout}{run=r3;out=g1}{title=Goal after line 3,width=6cm}
1 subgoal

========================
is_true (prime 17)
\end{coqout}

The statement of the example is processed by type inference,
it is enforced to be a type, but \lstinline/(prime 27)/ is actually
a term of type \lstinline/bool/.  Early in the library the
function \lstinline/is_true/ is declared as a coercion from
\lstinline/bool/ to \lstinline/Prop/ and hence is it inserted
by \Coq{} automatically.

\begin{coq}{name=istruedef}{}
Definition is_true b := b = true.
Coercion is_true : bool >-> Sortclass. (* Prop *)
\end{coq}

Another coercion that is widely used injects booleans into naturals.
Two examples follow.
\marginnote{Mention Kronecker delta as a math example of the same hack}

\begin{coq}{name=natofbool}{}
Variable T : eqType.
Fixpoint count (a : pred T) (s : seq T) :=
  if s is x :: s' then a x + count a s' else 0.
Lemma count_uniq_mem (s : seq T) x :
  uniq s -> count_mem x s = (x \in s).
\end{coq}
\coqrun{name=ex}{ssr,istruedef,natofbool,abort}

In line number 2 the term \lstinline/(a x)/ is a boolean.  The
\lstinline/nat_of_bool/ function is automatically inserted to turn
\lstinline/true/ into 1 and \lstinline/false/ into \lstinline/0/.
Similarly, in the last line the membership test is turned into
a number, that is shown to be equivalent to the count of any
element in a list that is duplicate free.

Another example of a coercion that is related to the running example
of the current chapter is \lstinline/sort/.  Typically the projection
of a record type extracting the data type is declared as a coercion
letting one state generic theorems like in the following example.

\begin{coqdef}{name=sotc}
Lemma example (e : eqType) : forall x y : e, x == y -> y == x.
\end{coqdef}
\begin{coq}{def=sotc}{}
Lemma example (e : eqType) : forall x y : e, x == y -> ...
\end{coq}
\coqrun{name=r5}{ssr,sotc,abort}

Here the type of \lstinline/x/ and \lstinline/y/ is
\lstinline/(sort e)/ and not \lstinline/e/ as the user initially wrote.
Indeed \lstinline/e/ is a term (of type \lstinline/eqType/) while
the \lstinline/forall/ quantification expects a type after the
colon.  The \lstinline/sort/ function mapping an \lstinline/eqType/
into a \lstinline/Type/ is inserted automatically.

Coercions are composed transitively.

\begin{coq}{name=b2z}{}
Definition zerolist n := mkseq (fun _ => 0) n.
Coercion zerolist : nat >-> seq.
Check 2 :: true == [:: 2; 0].
\end{coq}
\coqrun{name=r6}{ssr,b2z}

For the convenience of the reader we list here the most widely
used coercions. there are also a bunch on Funclass not listed
and elimT surely deserves some explanation.

\noindent
\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,center
	title,tabularx={l|l|l},fonttitle=\sffamily\bfseries,title=Coercions]
coercion & source & target \\ \hline
\lstinline/Posz/ & \lstinline/nat/ & \lstinline/int/ \\
\lstinline/nat_of_bool/ & \lstinline/bool/ & \lstinline/nat/ \\
\lstinline/elimT/ & \lstinline/reflect/ & \lstinline/Funclass/ \\
\lstinline/isSome/ & \lstinline/option/ & \lstinline/bool/ \\
\lstinline/is_true/ & \lstinline/bool/ & \lstinline/Sortclass/ \\
\hline
\end{tcolorbox}

\marginnote{This may go in Chapter 1}
Another device that is used to help type inference is the
\lstinline/Implicit Types/ directive.  This directive lets
one attach a default type to variable names.

\begin{coq}{name=itype}{title=Example of \lstinline/Implicit Types/}
Implicit Types m n : nat.
Check forall m n, n == m.
\end{coq}
\coqrun{name=r7}{ssr,itype}

In the example above the statement we \lstinline/Check/ does not
contain enough information alone to be well types.  The overloaded
\lstinline/==/ notation needs the terms to which it is applied to
have a type for which a \lstinline/Canonical Structure/ is declared.
Even if we did not annotate \lstinline/n/ and \lstinline/m/ with a
type, the directive on the first line does it for us.

The reader already familiar with the concept of coercion
may find the presentation of this chapter nonstandard.
Indeed coercions are usually presented as a device to model
subtyping in a theory that, like \mcbCIC{}, does not
feature subtyping.  As we will see in Chapter~\ref{ch:hierarchy}
the role played by coercions is in the modelling of the hierarchy
of algrabraic structure is minor.  Indeed what is hard is not to
forget some fields of a structure to obtain a simpler one.  What
is hard is to reconstruct the missing fields of a structure
or compare two structures finding the minimum super structure.
These tasks are mainly implemented using canonical structures.
