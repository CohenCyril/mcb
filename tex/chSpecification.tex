\chapter{More statements, more proofs}{Advanced specifications}

in addition to the photos:
\begin{itemize}
\item talk about /= in 2 as a decorator for elim on a list (since arithmetics is all loked with nosimpl).
\item talk about nosimpl in 3.3, say that according to our experience simpl is not
always a good idea hence nosimpl.
\item good practice (3.3 or 3.4): state and prove the fixpoint unfolding/folding
equations.
\end{itemize}

\section{Type Theory}

\subsection{Curry-Howard correspondance for propositional logic}

In TT proofs are terms terms and statements are types.
In particular inductive data types like the ones we programmed with in
the previous chapters can be used to describe the usual logical
connectives and atomic predicates.

First, A -> B, then forall x : A, Bx.  \C{fun x : A => b} as the constructor
of the function space.

\begin{center}
\AxiomC{$A$}
\noLine
\UnaryInfC{$B$}
\RightLabel{$\to_I$}
\UnaryInfC{$A \to B$}
\DisplayProof
\end{center}

\begin{center}
\AxiomC{$B$}
\RightLabel{$\forall_I$ ($x$ fresh)}
\UnaryInfC{$\forall x, B$}
\DisplayProof
\end{center}

For example the connective and is usually described by the introduction rule

\begin{center}
\AxiomC{$A$} \AxiomC{$B$}
\RightLabel{Conj}
\BinaryInfC{$A \wedge B$}
\DisplayProof
\end{center}

We call such rule Conj.  In Coq

\begin{coq}{name=And}{}
Inductive And (A B : Prop) : Prop :=
| Conj (pa : A) (pb : B)
\end{coq}

Here A and B are parameters ranging over logical propositions (Prop),
exactly as the rule above is a schema (on A and B). The single constructor
of And plays the role of the intro rule: to create a term of type And
you must use Conj, exactly as to Create a term of type A*B you must use
pair.  Indeed

\begin{coq}{name=And}{}
Infix "/\" := And.
About Conj : forall A B : Prop, A -> B -> A /\ B.
\end{coq}

Repeat that argument passing is like instantiation.

We have seen how to inspect pairs and extract the components. Given that
also the proofs of And are data we can do the same.

\begin{coq}{name=Ande1}{}
Definition elimAndleft A B (ab : A /\ B) : A :=
match ab with
| Conj a _ => a
end.
About elimAndleft : forall A B, A /\ B -> A.
\end{coq}

Pattern matching implements elimination

$$
\frac{A \wedge B}{A}elim\_left
$$

We do the same with Or.

What are tactics?  Tactics are commands that build proofs, hence
they construct terms.  E.g. \C{apply}, \C{case} on \C{nat},
\C{split}, \C{left}, \C{right}, for intro rules.  \C{case} tactic as
the only elim rule (for all inductives, since it is always a match).

A simple exercise to show "curryfication" and take that as an excuse
to prefer the curryfied form.

Inductives for \C{True}, \C{False} (elimination principle is ex falso
quod libet). Definition of \C{not}.

\subsection{Curry-Howard for quantifiers}
Dependent types and CH for forall.

CH for exists, like conj but dependent.

\begin{coq}{name=Ex}{}
Inductive Ex A (P : A -> Prop) : Prop :=
| exI (a : A) (pa : P a).
About exI.
\end{coq}

\begin{itemize}
\item Again \C{case} as the eliminator and the  \C{exists} tactic.

\item Her come the more complex the explaination of \C{=>} and
\C{:}. Warning the \C{:} of \C{apply:} is of a different nature (but
not the one of \C{apply/view:})...

\item General intro patterns: casing brackets \C{[]}, \C{ ->, _},
  \C{/lemma, /(_ x)}. For an example of \C{/lemma}, see \C{/ltnW} in
  \C{ltn_trans}.
\end{itemize}

\subsection{Curry-Howard correspondance for inductive reasoning}

CH: how to inhabit the type of induction on nat.
elim applies such principle.
\begin{itemize}
\item  This is recursive programming.
\item Mention case analysis as match.
\item Complex \C{elim} like \C{elim: {2}n (leqnn n)}.
\end{itemize}
\subsection{Constructivism}

TT is constructive.  As for nat and bool the \emph{only} way
to ... also for proposition. Eg. exists can only be proved
by exhibiting the witness and a proof that is satisfies the predicate.

It is pretty clear that our proofs are programs, we used match and fix
to prove exactly as we used them to program.

Stress the difference with proofs that use a classical axiom, like
excludded middle.
Show the example of a proof like the irrationality of $a ^b$, in
order to convey the idea that existential proofs demand a concrete
witness in this logic, which cannot in general be constructed without
resorting to someting else than what we presented so far, for instance
an axiom.



\section{Boolean reasoning, \C{Prop} reasoning, going back and forth}



\subsection{Motivations for boolean reflection}

As described on the picture 1:
\begin{itemize}
\item We now have two ways to express logical statements, and we just
  saw they are different (EM).
\item The first one is \C{bool},
  with \C{true, false : bool : Type}.
  It is a datatype with case analysis and computation (hence automation)
  available, which is good. And we can use \C{bool} to express some
  statements like \C{b1 && b2 = b2 && b1}. The other is \C{Prop}, with
  \C{? : P : Prop}. It is a sort, inhabited by statements, which are
  (possibly) themselves inhabited by proofs built by deduction. The
  later is necessary as bool does not capture all the statements we
  would like to work with. But can we bring the good points of
  \C{bool} in the \C{Prop} world when it is possible? For this purpose
  we need:
  \begin{itemize}
    \item We need to send \C{b1 && b2} to \C{Prop}: we do it via
      \C{is_true}.
    \item We need to relate \C{&&} and \C{/\\}.
  \end{itemize}
  By the way, in \C{bool}, the only proof term is \C{erefl true} (this
  is called UIP), which comes handy when crafting data structures that
  pair a data with a spec (comprehension style). We do not comment
  more but this will be expanded in chapter~\ref{ch:sigmabool}.
\end{itemize}

\subsection{The \C{is_true} coercion}

The \C{is_true} coercion gives the illusion of inhabiting a \C{bool}.
Hence one can use rewriting.

\subsection{Equivalences between booleans and \C{Prop} statements}

As described on the picture 2:
\begin{itemize}
\item The intented meaning is \C{b = true <-> P}. But this is not
  convenient in practice to model case analysis on \C{P}, which
  becomes logically justified. So we are going to craft an alternate
  formulation of the same fact: just like in math it is common to
  present several equivalent forms of a same definition, to be used in
  different contexts.

\item Second try: \C{(b = true /\\ P) \\/ (b = false /\\ ~ P)}. Nicer
  but we still have some remaining bureaucracy with conjunctions.

\item Next try: an ad hoc inductive predicate:

\begin{coq}{}{}
Inductive |*reflect*| (P : Prop) (b : bool) : Prop :=
|ReflectT (p : P)    (e : b = true)
|ReflectF (np : ~ P) (e : b = false)
\end{coq}

\marginnote{We will put \C{reflect} in \C{Type} only in Chapter
  \ref{ch:sigmabool}, when describing \C{insub}.}
Better to drive proofs with EM (however we will later refine this one
once more, and this refinement will be relevant to all the spec
lemmas).

\item First examples: \C{andP}, \C{orP}, \C{implyP} with proofs by
  case analysis of the truth tables.
\end{itemize}
These are called views.

\subsection{Prove and use views}

\begin{itemize}

\item Example of \C{eqnP}, that is \C{eqP} specialized to
  \C{nat}. Proof using \C{(iffP idP)}. Explain \C{iffP} and \C{idP} is
  the dummay case.

\item Another example: Simplified instance of \C{inj_eqAxiom} in
  section  \C{TransferEqType} of \C{eqtype.v}, with \C{nat} as
  codomain. Proof with \C{(iffP eqnP)}.

\item Using views, with tactics. First, example of using \C{eqnP} in
  an intro pattern, like \C{=> /eqnP ->}. Note that the direction in
  which the view should be used has been guessed
  automatically. Explain which adapter has been inserted (as a hint).

\item Then show the cute proof of \C{leq_total}, which features
  \C{apply/implyP}.

\item Finally, show \C{case/orP: (leq_total n m)}. May be a first
  simple and dummy example. Then one possibility is
  to show a simplified version of the proof of \C{leq_max}, removing
  the \C{without loss}. This features \C{case/orP: (leq_total n2 n1)}
  and \C{rewrite (maxn_idPl le_n21)} which uses the \C{elimT} coercion.
  This could be reused in the next section, to illustrate \C{wlog}.


\item There are more adaptors than \C{introT, introF, elimT, elimF},
  in particular with negations \C{elimN,...} and \C{apply/v1/v2}.

\end{itemize}

Rmk: Still missing: \C{/andP [h1 h2]} and \C{=> /v1 /v2} (may be the
last one comes earlier).

% It is the fragment of decidable stuff (EM as case).
% It is a concrete data type on which you can program (SSR), automation by
% computation.

% % \begin{coq}{name=Ex}{}
% % Lemma muln_eq0 m n :
% %   ((m * n = 0) -> (m = 0) \/ (n = 0)) /\
% %   ((m = 0) \/ (n = 0) -> (m * n = 0))
% % Proof.
% % Qed.
% %
% % Lemma leq_mul2l m n1 n2 :
% %   (m * n1 <= m * n2) = (m == 0) || (n1 <= n2).
% % Proof.
% % Qed.
% % \end{coq}



% \begin{coq}{name=Ex}{}
% Lemma leq0n n : (0 <= n) (* = true *).
% \end{coq}

% NOt everything can be in bool, e.g. exists or a real reasoning by cases
% on a disjunction. Inductives give you the tree structure in natural
% deduction, not bools.

% \begin{coq}{name=Ex}{}
% Lemma ...
% case/orbP : (leq_total n m)
% \end{coq}

% We need lemmas to relate

% \begin{coq}{name=Meaning of reflect}{}
% Definition reflect P b : Prop :=  b -> P /\ P -> b

% Lemma orbP p q : reflect (p \/ q) (p || q).
% \end{coq}

% so frequent and so many variations that we have proper infrastructure like
% being able to invoke views everywhere and have 1 view per connective (negate or
% not...).

% \begin{coq}{}{}
% Lemma introT  : P -> b.            Proof using Pb. exact: introTF true _. Qed.
% Lemma introF  : ~ P -> b = false.  Proof using Pb. exact: introTF false _. Qed.
% Lemma introN  : ~ P -> ~~ b.       Proof using Pb. exact: introNTF true _. Qed.
% Lemma introNf : P -> ~~ b = false. Proof using Pb. exact: introNTF false _. Qed.
% Lemma introTn : ~ P -> b'.         Proof using Pb'. exact: introTFn true _. Qed.
% Lemma introFn : P -> b' = false.   Proof using Pb'. exact: introTFn false _. Qed.
% \end{coq}

% \subsection{how to use reflect lemmas as tactic decorators}

% we make examples with andP orP negP in move/P, apply/P, case/P.

% we explain the hint view, plus the extra impl arguments.

% some view can be partial, A -> B -> reflect B c.

% \subsubsection{The view mechanism in intro pattern}

%   a == b \&\& bb

% views applied to top, inline destructuring and subst:
%   => /andP[/eqP-> pb] ->.

% Fwd and backward declarative steps.
% have : P x := ... H ...
% suff.

% Handling symmetries:
% gen have: x Hx / P x.

% managing large goals and contexts: set, -/x /x

% help the reader with typographical comments, like leaving an empty
% line in latex (here we use bullets).

Not everything needs to be a tactic, the logic is powerful
enough to express special connectives that induce a line of
reasoning. Hence the next section.

\section{Advanced, practical, statements}

general talk about the fact that statements/definition do matter: not only for
their meaning but also because they have implications on the
usability/practicality in the rest of the library.  At least two classes of
techniques, the ones based on the logic (bool refl, reflect, classically, order
of forall when instantiation done via CH) and the ones based on the support of
the prover (implicit args, type inference CS, Hint Resolve).

More in general, this has to be mentioned in the main intro of the book, here
we revise the idea.

What we did for reflect, an ad hoc connective, to model a line of reasoning is
a recurrent pattern in the \mcbMC{} library: the ``spec'' predicates.  Specs
are particularly handy  because inductive predicates, via their elimination
rule, accesses a special feature of the type theory of Coq: implicit equations
/ automatic substitution.

If we look at reflect, and its use, one is very likely to substitute b
for its value in each branch of the case.

\begin{coq}{}{}
Inductive |*reflect*| (P : Prop) (b : bool) : Prop :=
|ReflectT (p : P)    (e : b = true)
|ReflectF (np : ~ P) (e : b = false)
\end{coq}

This alternative formulation makes the equation implicitly stated and
also automatically substituted during case analysis.

\begin{coq}{}{}
Inductive |*reflect*| (P : Prop) : bool -> Prop :=
|ReflectT (p : P)    : reflect P true
|ReflectF (np : ~ P) : reflect P false
\end{coq}

Here the second argument of \C{reflect} is said to be an \emph{index}
and it is allowed to vary depending on the constructor: \C{ReflecT} always
builds a term of type \C{(reflect P true)} while \C{ReflectF} builds
a term of type \C{(reflect P false)}.
Example:

\begin{coq}{}{}
case: (andP a b) => [ab|nab]
\end{coq}

\begin{coqout}{}{width=6cm}
a, b : bool
============================
a && b ==> (a == b)
\end{coqout}
\begin{coqout}{}{width=6cm}
a, b : bool
ab : a /\ b
============================
true || a == b

subgoal 2 is:
false || a == b
\end{coqout}

Every time a term of type \C{(reflect (a /\\ b) (a && b))} is eliminated, the
following happens:
\begin{enumerate}
\item 2 subgoals are generated
\item in the first one (corresponding to \C{ReflectT}) a new hyp is
  available (\C{(a /\\ b)}) and all occurrences of the boolean
  expression \C{(a && b)} are replaced by \C{true} (the value of the index
  for \C{ReflectT}).
\item in the first one (corresponding to \C{ReflectF}) a new hyp is
  available (\C{\~(a /\\ b)}) and all occurrences of the boolean
  expression \C{(a && b)} are replaced by \C{false}, the value of
  the index for \C{ReflectF}.
\end{enumerate}

The second goal becomes trivial, hence we can finish

\begin{coq}{}{}
case: (andP a b) => [[-> ->] | //]
\end{coq}

An even better tactic is

\begin{coq}{}{}
case: (andP _ _) => [[-> ->] | //]
\end{coq}

In this case the boolean expression replaced by true/false is \C{(_ && _)}.
Trailing \C{_} are also added automatically by \C{case} leading to the
idiomatic

\begin{coq}{}{}
case: andP => [[-> ->] | //]
\end{coq}

Note the similarity between matching \C{(_ && _)} and the job of rewrite.

On the same line, we present \C{leqP} that still models a case split but
this time specialized to the order relation (and its negation) substituting
both with true/false.  Just mention \C{ltngtP}, that is the proof that
a boolean predicate (because of its 2 valued nature) can model a concept
with 3 cases as well via this spec mechanism.  Or that the same concept,
depending on the proof you need to do, may benefit from different natures
of case splits.

\mantra{the structure of the proof shall not be driven by the syntax (head
symbol) of the definition/predicate under study but by the view/spec you apply
to it}

Just show a use of \C{ifP} and/or \C{ifPn} and the fact that its pattern is
quite smart/small wrt the expression it typically handles (3 chars in place of\\
\C{(if cond then branch else alternative)}).

Also show the adaptor altP, that is particularly useful with eqnP and boolP.

\subsection{TBD: dependent elimination (**)}

explain return match clause.  Maybe just the syntax we provide here and
there, the / annotation for elim/case, and then point to other texts explaining
the thing.  \mcbMC{} does not use such thing but for spec.

\subsection{other tools?}

\begin{itemize}
\item Use macros (\C{left_commutative} or notations like
\C{\{in A, bijective f\}}, and3, ...)
\item Use naming conventions
\item Classically (do not insist too much)
\item iff (\C{AGM}): find examples?
\item Tuning of implicit arguments
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Towards real proofs}

Real proofs also deal with structure (readability, naming, context handling and
robustness), repetitions (like symmetry).  This section works out a few
examples illustrating good practices and specific proof commands.

Example:
$$
\forall n_1, n_2, m, \quad m \le max(n_1,n_2)
\Leftrightarrow m \le n_1 \textrm{ or } m \le n_2
$$

The proof goes like that: without loss of generality we can assume that
$n_2$ is greater or equal to $n_1$, hence $n_2$ is the maximum between
$n_1$ and $n_2$.  Under this assumption it is sufficient to check
that $m \le n_2$ holds iff either $m \le n_2$ or $m \le n_1$.
The only non trivial case is when we suppose $m \le n_1$ and
we need to prove $m \le n_2$ which holds by transitivity.\hfill$\square$

As usual we model double implication as an equality between two
boolean expressions:

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
\end{coq}

The proof uses the following (new) lemmas.  Pay attention to
\C{orb_idr}.

\begin{coq}{}{title=tools}
Lemma orb_idr (a b : bool) : (b -> a) -> a || b = a.
Lemma maxn_idPl {m n} : reflect (maxn m n = m) (m >= n).
Lemma leq_total m n : (m <= n) || (m >= n).
\end{coq}

Our first take takes no advantage of the symmetry argument and
begins by reasoning by cases on the order relation,
we name the resulting hyp with a meaningful name and close to
the proof step that generates it (to ease tracking who adds what).

\begin{coq}{}{}
Proof.
case/orP: (leq_total n2 n1) => [le_n21|le_n12].
  rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
  by apply: leq_trans le_mn2 le_n21.
rewrite maxnC orbC.
rewrite (maxn_idPl le_n12) orb_idr // => le_mn1.
by apply: leq_trans le_mn1 le_n12.
Qed.
\end{coq}

alternative with a more declarative have

\begin{coq}{}{}
Proof.
have /orP[le_n21|le_n12] := leq_total n2 n1.
  rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
  by apply: leq_trans le_mn2 le_n21.
rewrite maxnC orbC.
rewrite (maxn_idPl le_n12) orb_idr // => le_mn1.
by apply: leq_trans le_mn1 le_n12.
Qed.
\end{coq}


2 goals, hence indentation.

\begin{coqout}{}{title=Output line 3,width=8cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
============================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal 2 is:
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

The first goal is simplified by
reqriting with the \C{maxn_idPl} view (recall elimT).  Then
\C{orb_idr} trivializes the main goal and generates a side condition
with an extra hyp we name \C{le_mn2}

\begin{coqout}{}{title=Output line 4a,width=6.7cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
============================
(m <= n1) = (m <= n1) || (m <= n2)

subgoal 2 is: ...
\end{coqout}
\begin{coqout}{}{title=Output line 4b,width=5.3cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
le_mn2 : m <= n2
============================
m <= n1

subgoal 2 is: ...
\end{coqout}

Line 3 combines by transitivity the two hyps to conclude.
Since it closes the proof branch we use the prefix \C{by}
to asserts the goal is solved and visually signal the end of the paragraph.
(maybe use \C{exact}).

Line 4 commutes the max and or, hence we can copy paste the first paragraph
also to close the second goal.

Next take factorizes a generalization of goal to take care of symmetry.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
have th_sym x y: y <= x -> (m <= maxn x y) = (m <= x) || (m <= y).
  move=> le_n21; rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
  by apply: leq_trans le_mn2 le_n21.
by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
Qed.
\end{coq}

Last line instantiates \C{th_sym} \emph{in each branch} using the corresponding
hypothesis on \C{n1} and \C{n2} generated by the case analysis.

\begin{coqout}{}{}
2 subgoals
m, n1, n2 : nat
th_sym : forall x y : nat,
         y <= x -> (m <= maxn x y) = (m <= x) || (m <= y)
============================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2) ->
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal 2 is:
(m <= maxn n2 n1) = (m <= n2) || (m <= n1) ->
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

This is exactly what is needed in the first branch of the case analysis.
The last subgoal just requires commuting \C{max} and \C{||}.

We prefer to get rid of the easiest part of the proof first, thus
keeping the main branch of the proof non indented. In this case
it amounts to begin by showing why \C{th_sym} suffices to prove the main
goal.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
suff th_sym x y: y <= x -> (m <= maxn x y) = (m <= x) || (m <= y).
  by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
move=> le_n21; rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
by apply: leq_trans le_mn2 le_n21.
Qed.
\end{coq}

Final step, wlog lets us not repeat the goal and abstract it, but
just mention the extra assumption we can take without loosing
generality.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof
wlog le_n21: n1 n2 / n2 <= n1 => [th_sym|].
  by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
by apply: leq_trans le_mn2 le_n21.

by rewrite /maxn le_n21 orb_idr // => le_mn2; apply: leq_trans le_mn2 le_n21.

(* then, recalling apply adds _ we can avoid naming/mentioning le_mn2*)
by rewrite (maxn_idPl le_n21) orb_idr // => ?; apply: leq_trans le_n21.

(* or even better using lemmas in intro pattern + auto generalization
   plus rewriting an is_true... or maybe not *)
by rewrite (maxn_idPl le_n21) orb_idr // => /leq_trans->.
Qed.
\end{coq}

For wlog, say that the block naming \C{th_sym} is optional and frequently
omitted (at the cost of less explicit script).

\begin{coq}{}{}
Lemma edivnP m d :
 let ed := edivn m d in
   ((d > 0) ==> (ed.2 < d)) && (m == ed.1 * d + ed.2).
Proof.
move E: (edivn m d) => ed /=.
case: d => [|d /=] in E *; first by rewrite -E eqxx.
rewrite /edivn /= in E.
rewrite -[m]/(0 * d.+1 + m).
elim: m {-2}m 0 (leqnn m) E => [|n IHn] [??<-|m] //= q le_mn.
rewrite subn_if_gt; case: (leqP d m) => [le_dm|lt_md <- /=]; last first.
  by rewrite ltnS lt_md eqxx.
have le_mdn : m - d <= n by rewrite (leq_trans (leq_subr d m)).
by move/(IHn _ _ le_mdn); rewrite mulSnr -addnA -subSS subnKC.
Qed.
\end{coq}

May be a real 10 lines proofs would help here. Lemmas about Euclidean
division?
 \begin{itemize}
\item Proofs have a structure, to ensure readability (in a certain
  sense) and maintenance; we list here some tools and good practice.
\item Declare intermediate steps: forward (\C{have}), backward
  (\C{suff}), symmetries (\C{gen have} and mention \C{wlog}),
abbreviations \C{set}
\item: Punctuation to help the reader: bullets, indentation,
  terminating tactics.
\item Good practices: local/early error detection, checkpoints via
  \C{have}, naming policies (lemmas, but also hypotheses and bound
  variables), robust rewrite.
\item keep context clean?
\end{itemize}

\section{STOP HERE}

THIS CHAPTER IS ABOUT METHODOLOGY, plus introduces the other logical
connectives. May be merged into the previous chapter.


% Where one learns to do proofs.
% Boolean reflection in practice, views, discussion on the definition of leq,
% proofs on things defined in the
% previous chapter, associated tactics, exercises on prime, div,
% binomial, etc.
%
% spec? A new vernacular to declare specs without typing coinductive and
% by writing explicitly the equations.

Discussion prop/bool, intuitionism, extraction (we should be able to
avoid talking about impredicativity, but use Prop for computationally
irrelevant).


\begin{itemize}
\item can we specify all we have written so far using just = and forall? No.
	Example dvdn needs exists to be specified
\item exists, and, or, neg, False, True as inductives (again CH style)
\item related tactics: split, left, right,exists,case
\end{itemize}

Anyway to take advantage of computation (ssr style) we want to
work with bool as much as possible:

\begin{itemize}
\item reflect is the right way to write iff, <->, specialized to bool
	so that the proof language recognizes it and offer a bit more ergonomic
\item is-true
\item infrastructure for reflect: iffp, altp
\item no split if goal is \&\& (metodology)
\end{itemize}

Writing good statements

\begin{itemize}
\item = as iff for bool, because rewrite is easy to use
\item and3p, spec (drive your proof),
\item advanced stuff: classically P instead of not-not P (can be
  skipped for beginners)
\item in general good quantifications and implicit arguments and good library
	makes it possible to work without evars
\item . \C{<=} . ?= iff .
\end{itemize}

Statements do also occur in the middle of proofs.  There we have many ways to
write them compactly, wlog and have.

Comparison with other possible ways of writing properties:
\begin{itemize}
\item impact of le v.s. leq in a proof
\end{itemize}

In this chapter we should distill a description of our
systematic-reactions, reflexes, to typical situations a
beginner would screw up. In fact it would be great to explain here the
mix of Gallina (unless, classically, etc.) and of tactics (wlog,
have,...) that lead to a convenient modelling of the math prose.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Declaring implicit arguments}
\mcbREQUIRE{Canonical}
\mcbPROVIDE{stating lemmas}
\mcbLEVEL{2}
\mcbsection{Declaring implicit arguments}\label{sec:declaringimpl}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

here we describe how to choose which arguments are implicit,
that one has to think ahead how  a lemma is used and hence
which data type inference has at hand.  Also that the order
of quantifiers is relevant.
\begin{itemize}
\item lemmas: fwd/backward reasoning
\item equations, look at the concl too, free vars are abstracted
\item compare with eapply style
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Coercions}
\mcbREQUIRE{}
\mcbPROVIDE{}
\mcbLEVEL{1}
\mcbsection{Notational aspects of specifications}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Even if the main way to extend the type inference algorithm
% is via Canonical Structures, another mechanism is available
% and used all over the library, even if it plays a minor role.
% The language of Canonical Structures lets one program how the value of
% an implicit argument can be synthesized, but can hardly be used to
% explain \Coq{} how to ``fix'' an ill-typed term written by the user.

When a typing error arises, it always involves three objects:
a term \lstinline/t/, its type \lstinline/ity/ and the type
expected by its context \lstinline/ety/.  Of course, for this
situation to be an error, the two types \lstinline/ity/ and
\lstinline/ety/ do not compare as equal.
The simplest way one has to explain \Coq{} how to fix \lstinline/t/,
is to provide a functional term \lstinline/c/ of type
\lstinline/(ity -> ety)/ that is inserted around \lstinline/t/.
In other words, whenever the user writes \lstinline/t/ in a context
that expects a term of type \lstinline/ety/, the system instead of
raising an errors replaces \lstinline/t/ by \lstinline/(c t)/.

A function automatically inserted by \Coq{} to prevent a type
error is called \emph{coercion}.
The most pervasive coercion in the \mcbMC{} library is
\lstinline/is_true/ that lets one write statements using boolean
predicates.\marginnote{I guess in a way or another is true has
already been introduced}.

\begin{coqdef}{name=istrue}
Lemma example : prime 17.
Proof.
Set Printing Coercions. Redirect "g1" Show.
by [].
Qed.
\end{coqdef}
\begin{coq}{def=istrue}{title=Coercion \lstinline/is_true/,width=6cm}
Lemma example : prime 17.
Proof.  by [].  Qed.
\end{coq}
\coqrun{name=r3}{ssr,istrue}
\begin{coqout}{run=r3;out=g1}{title=Goal after line 3,width=6cm}
1 subgoal

============================
is_true (prime 17)
\end{coqout}

The statement of the example is processed by type inference,
it is enforced to be a type, but \lstinline/(prime 27)/ is actually
a term of type \lstinline/bool/.  Early in the library the
function \lstinline/is_true/ is declared as a coercion from
\lstinline/bool/ to \lstinline/Prop/ and hence is it inserted
by \Coq{} automatically.

\begin{coq}{name=istruedef}{}
Definition is_true b := b = true.
Coercion is_true : bool >-> Sortclass. (* Prop *)
\end{coq}

Another coercion that is widely used injects booleans into naturals.
Two examples follow.
\marginnote{Mention Kronecker delta as a math example of the same hack}

\begin{coq}{name=natofbool}{}
Variable T : eqType.
Fixpoint count (a : pred T) (s : seq T) :=
  if s is x :: s' then a x + count a s' else 0.
Lemma count_uniq_mem (s : seq T) x :
  uniq s -> count_mem x s = (x \in s).
\end{coq}
\coqrun{name=ex}{ssr,istruedef,natofbool,abort}

In line number 2 the term \lstinline/(a x)/ is a boolean.  The
\lstinline/nat_of_bool/ function is automatically inserted to turn
\lstinline/true/ into 1 and \lstinline/false/ into \lstinline/0/.
Similarly, in the last line the membership test is turned into
a number, that is shown to be equivalent to the count of any
element in a list that is duplicate free.

Another example of a coercion that is related to the running example
of the current chapter is \lstinline/sort/.  Typically the projection
of a record type extracting the data type is declared as a coercion
letting one state generic theorems like in the following example.

\begin{coqdef}{name=sotc}
Lemma example (e : eqType) : forall x y : e, x == y -> y == x.
\end{coqdef}
\begin{coq}{def=sotc}{}
Lemma example (e : eqType) : forall x y : e, x == y -> ...
\end{coq}
\coqrun{name=r5}{ssr,sotc,abort}

Here the type of \lstinline/x/ and \lstinline/y/ is
\lstinline/(sort e)/ and not \lstinline/e/ as the user initially wrote.
Indeed \lstinline/e/ is a term (of type \lstinline/eqType/) while
the \lstinline/forall/ quantification expects a type after the
colon.  The \lstinline/sort/ function mapping an \lstinline/eqType/
into a \lstinline/Type/ is inserted automatically.

Coercions are composed transitively.

\begin{coq}{name=b2z}{}
Definition zerolist n := mkseq (fun _ => 0) n.
Coercion zerolist : nat >-> seq.
Check 2 :: true == [:: 2; 0].
\end{coq}
\coqrun{name=r6}{ssr,b2z}

For the convenience of the reader we list here the most widely
used coercions. there are also a bunch on Funclass not listed
and elimT surely deserves some explanation.

\noindent
\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,center
	title,tabularx={l|l|l},fonttitle=\sffamily\bfseries,title=Coercions]
coercion & source & target \\ \hline
\lstinline/Posz/ & \lstinline/nat/ & \lstinline/int/ \\
\lstinline/nat_of_bool/ & \lstinline/bool/ & \lstinline/nat/ \\
\lstinline/elimT/ & \lstinline/reflect/ & \lstinline/Funclass/ \\
\lstinline/isSome/ & \lstinline/option/ & \lstinline/bool/ \\
\lstinline/is_true/ & \lstinline/bool/ & \lstinline/Sortclass/ \\
\hline
\end{tcolorbox}

\marginnote{This may go in Chapter 1}
Another device that is used to help type inference is the
\lstinline/Implicit Types/ directive.  This directive lets
one attach a default type to variable names.

\begin{coq}{name=itype}{title=Example of \lstinline/Implicit Types/}
Implicit Types m n : nat.
Check forall m n, n == m.
\end{coq}
\coqrun{name=r7}{ssr,itype}

In the example above the statement we \lstinline/Check/ does not
contain enough information alone to be well types.  The overloaded
\lstinline/==/ notation needs the terms to which it is applied to
have a type for which a \lstinline/Canonical Structure/ is declared.
Even if we did not annotate \lstinline/n/ and \lstinline/m/ with a
type, the directive on the first line does it for us.

The reader already familiar with the concept of coercion
may find the presentation of this chapter nonstandard.
Indeed coercions are usually presented as a device to model
subtyping in a theory that, like \mcbCIC{}, does not
feature subtyping.  As we will see in Chapter~\ref{ch:hierarchy}
the role played by coercions is in the modelling of the hierarchy
of algrabraic structure is minor.  Indeed what is hard is not to
forget some fields of a structure to obtain a simpler one.  What
is hard is to reconstruct the missing fields of a structure
or compare two structures finding the minimum super structure.
These tasks are mainly implemented using canonical structures.
